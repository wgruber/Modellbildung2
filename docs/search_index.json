[
["index.html", "Statistik mit R für Fortgeschrittene", " Statistik mit R für Fortgeschrittene Walter Gruber 2019-05-09 "],
["vorbemerkung.html", "Vorbemerkung", " Vorbemerkung Dieses Skriptum wurde mit dem Paket bookdown erstellt. Der verwendete R-Code wird als Teil des Skriptums angeführt und kann auch direkt von diesem Dokument in ein R-Skript übernommen und ausgeführt werden. Erläuterungen zum Code beschränken sich zum Teil auf wesentliche Code-Fragmente. Für detaillierte Angaben zu diversen Funktionen ist die R-Hilfe zu verwenden. Der nachfolgende Code ist spezifisch für die Erstellung dieses Dokumentes, sowie der Bearbeitung der Beispiele im Kurs von Bedeutung. Es wird in diesem Code-Teil sichergestellt, dass die verwendeten Pakte vorhanden und geladen sind. Daher sollte dieser Code am Anfang jeder neuen R-Datei übernommen werden. Die Vorgehensweise ist: Starten von R-Studio Öffnen einer neuen R-Script-Datei Kopiere die nachfolgenden Zeilen in diese Datei Speichere die Datei mit einem entsprechenden Namen Führe diesen Code aus Füge deinen Code nach diesen Zeilen ein # Initialisierung rm(list = ls()) if (!require(&quot;pacman&quot;)) install.packages(&quot;pacman&quot;) pacman::p_load(corrplot, DAAG, dataMaid, devtools, doBy, DT, ggformula, ggplot2, gridExtra, htmlwidgets, imager, knitr, labelled, leaps, magick, MASS, NHANES, mosaic, mosaicCore, mosaicData, pander, pastecs, ppcor, reshape2, rockchalk, rpart, rpart.plot) Des Weiteren ist es von Vorteil, zu Beginn einer Auswertung/Datenanalyse mit R eine entsprechende Verzeichnisstruktur im Windows-Dateimanager festzulegen und für diese Struktur ein R-Projektfile anzulegen. Die Verzeichnisstruktur richtet sich im Allgemeinen nach der jeweiligen Analyse, folgende Vorgaben haben sich aber bewährt: Abbildung 1: Dateistruktur für R-Projekt Die Root kann dabei entweder auf der lokalen Festplatte (C:/..) oder einem Server, bzw. Cloud (../NextCloud/R Modellbildung/Images) liegen. Das Anlegen eines R-Projektes wird im RStudio durchgeführt. Abbildung 2: R-Projekt definieren Nachdem bereits eine Verzeichnisstruktur definiert wurde, kann man das Projekt in das bereits definierte Verzeichnis legen (folge den Schritten die von RStudio vorgegeben werden). Den Vorteil des projektbasierten Arbeitens werden wir im Verlauf des Kurses noch näher kennen lernen. Inhalte, Beispiele und Daten stammen teilweise aus dem Internet, u.a. (Coursera 2018), (DataCamp 2018) und den Büchern (Field 2017), (Bühner 2009) und (Bühner 2017). Referenzen "],
["motivation.html", "Motivation", " Motivation Modelle werden meist dazu verwendet, um komplexe Sachverhalte zu beschreiben und Erklärungen für deren Wirkungsweise, Ursachen und Zusammenhänge zu finden. In diesem Seminar wollen wir uns mit der einfachen statistischen Modellbildung beschäftigen. Das Wesentliche und gleichzeitig auch das Schwierigste bei der Modellbildung ist die Identifizierung und Zuordnung der einzelnen Bausteine und nicht - wie oft angenommen - die einem statistischen Modell zugrundeliegende Mathematik. Obwohl die mathematischen Grundlagen für die Anwendung bestimmter Modellvorstellungen enorm wichtig und Kenntnisse darüber auch für die Abschätzung der Güte und Gültigkeit eines Modells erforderlich sind, spielen formale und mathematische Details in der Anwendung sehr oft nur eine nebensächliche Rolle. In diesem Seminar sollten die Ziele, Einschränkungen, Vor- und Nachteile statistischer Modelle anhand von theoretischen, aber auch praktischen Überlegungen näher gebracht werden. Die Klärung der zentralen Fragen jeder Art von Modellbildung stehen dabei im Vordergrund, d.h.: wie kann ich mit möglichst einfachen Mitteln die “Wirklichkeit” möglichst gut zu beschreiben? wie kann ich beurteilen, ob mein Modell gut ist (zumindest im Vergleich mit anderen Modellen)? wie kann ich die Wichtigkeit einzelner Modellbausteine beurteilen? welche Erkenntnisse darf ich aus meinem Modell auf die Wirklichkeit übertragen? "],
["variabilitat.html", "Variabilität", " Variabilität Bevor wir uns mit einzelnen Techniken und Verfahren der linearen Modellbildung auseinandersetzen, soll in einem kurzen Exkurs eines der grundlegensten Prinzipien der statistischen Modellbildung wiederholt und diskutiert werden - die Varianz von beobachten Werten. Eigentlich ist es die Variabilität von Merkmalen, die statistische Methoden für die Erklärung von Effekten überhaupt erst auf den Plan ruft. Würden Merkmale wie z.B. Leistung einer Person, Persönlichkeitsmerkmale, Wetter, Produktionsgenauigkeit etc. nicht schwanken/variieren, würden wir heute nicht in diesem Raum sitzen und uns mit statistischen Modellen beschäftigen. Der Begriff Variabilität ist für uns so alltäglich, dass wir ganz selbstverständlich damit umgehen. Doch was steckt wirklich dahinter? Wie können wir Sie nutzen um komplexere Eigenschaften einer Sache oder eines unerklärlichen Phenomäns auf die Spur zu kommen? Betrachten wir zunächst einmal ein sehr einfaches Beispiel. In den nachfolgenden Graphen sind (sehr vereinfacht) mehrere Möglichkeiten dargestellt, wie eine Person mitsamt Hund sich entlang einer Straße bewegt. Abbildung 1: Gassi gehen mit Blindenhund. Die blaue Linie beschreibt den Weg des Hundehalters, die Orange den des Hundes. Die Grüne Line ist die Referenzlinie, von welcher aus der Abstand zur jeweiligen Position (Hund und Mensch) zu sechs Beobachtungszeitpunkten gemessen wurde. Die Daten der Messungen sind in folgender Tabelle gegeben: Mensch Hund MenschD HundD KP ZMensch ZHund ZKP 4 3 0.83 1 0.83 0.71 0.71 0.5 5 4 1.83 2 3.66 1.56 1.42 2.22 2 1 -1.17 -1 1.17 -1 -0.71 0.71 3 2 -0.17 0 0 -0.15 0 0 2 0 -1.17 -2 2.34 -1 -1.42 1.42 3 2 -0.17 0 0 -0.15 0 0 In obiger Tabelle zeigen die Spalten Mensch und Hund jeweils den Abstand zur gedachten Beobachtungslinie pro Beobachtungszeitpunkt. Die Spalten MenschD und HundD ist jeweils die Differenz jeder Beobachtung zum jeweiligen Mittelwert aller Beobachtungen, also \\(MD_i = M_i - \\bar{M}\\) und \\(HD_i = H_i - \\bar{H}\\) mit \\(i \\in \\{1,6\\}\\). Die Spalte KP zeigt das Kreuzprodukt, also \\(KP_i = MD_i \\cdot HD_i\\) mit \\(i \\in \\{1,6\\}\\). Die Spalten ZMensch und ZHund entsprechen den \\(z\\)-transformierten Werten, also \\(z_i^M = (M_i - \\bar{M}) / sd(M)\\) und \\(z_i^H = (H_i - \\bar{H}) / sd(H)\\)) mit \\(i \\in \\{1,6\\}\\). Die Spalte ZKP entspricht dem Kreuzprodukt der z-Transformierten Werte, also \\(ZKP_i = ZM_i \\cdot ZH_i\\) mit \\(i \\in \\{1,6\\}\\). Statistische Kennwerte für obige Daten (Mittelwert, Varianz und Standardabweichung) sind in folgender Tabelle dargestellt: Mensch Hund MenschD HundD KP ZMensch ZHund ZKP Mean 3.167 2 -0.003 0 1.333 -0.005 0 0.808 Var 1.367 2 1.367 2 2.052 0.997 1.008 0.756 SD 1.169 1.414 1.169 1.414 1.433 0.998 1.004 0.869 Wenn also ein Hund jeder Bewegung der Person folgt und dabei auch stets denselben Abstand hält, sind deren beobachteten Pfade zwar örtlich gesehen unterschiedlich, aber die Varianz des einen erklärt vollständig die Varianz des anderen Pfades. Mit anderen Worten, die beiden Pfade zeigen eine perfekte Kovariation. Formal wird diese Kovariation als durchschnittliche Summe der Kreuzprodukte ermittelt, also (M = Mensch, H = Hund): \\(cov(M, H) = \\frac{\\sum_{i=1}^{6} (M_i - \\bar{M}) \\cdot (H_i - \\bar{H})}{N-1} = 1.60\\) Setzt man die Beispieldaten in diese Berechnungsvorschrift ein, erhält man für die Summe der Kreuzprodukte 8. Die Kovarianz der beobachteten Werte ist (als durchschnittliche Kreuzproduktsumme) somit \\(cov(M,H) =\\) 1.6. Die Korrelation berechnet sich dann ganz einfach zu: \\(r(M, H) = \\frac{cov(M,H)}{s_M \\cdot s_H} = \\frac{1.6}{1.169 \\cdot 1.414} = 0.968 \\simeq 1\\) Im vorliegenden Beispiel ergibt sich eine Korrelation \\(r(M,H) =\\) 0.97 (also eine positive und perfekte Korrelation). Der Korrelationskoeffizient hat gegebüber der Kovarianz den Vorteil, dass er durch die Normierung über die Standardabweichungen: einen (einheitenlosen) Wertebereich zwischen \\(r \\in [-1, 1]\\) aufweist und damit vergleichbar mit anderen Korrelationswerten wird. Als praktische Effektgröße interpretiert werden kann. Das Quadrat des Korrelationskoeffizienten (\\(r^2\\), auch Varianzaufklärung, Determinationskoeffizient genannt) Auskunft über die aufgeklärte Varianz gibt. Letzteres Maß spielt eine wesentliche Rolle sowohl bei der Korrelationsanalyse, als auch bei der multiplen Regression und anderen Verfahren. Die Bedeutung der Kovarianu sei anhand des verwendeten Beispiels nochmals verdeutlicht: Im Fall einer perfekten Kovarianz (also 100% Übereinstimmung der Bewegungen von Mensch und Hund), braucht man nur mehr die Bewegung einer Variablen zu wissen (z.B. die des Menschen), um die Bewegungen des Hundes zu bestimmen (erklären). Somit erklärt die Variabilität der Bewegung vom Menschen zu 100 % die Variabilität der Bewegungen des Hundes. Die Beziehung zwischen zwei (intervallskallierten) Variablen lässt sich am besten mit einem Streudiagramm darstellen: Die folgende Abbildung zeigt ein weiteres Mensch-Hund Beispiel: Abbildung 2: in diesem Beispiel scheint es sich um eine Hund zu handeln, der bestmöglich das Gegenteil vom Menschen macht. Bestmöglich dahingehen, dass er nicht nur in die genau entgegengesetzte Richtung ausweicht, sondern dabei auch auf den genauen Abstand der Abweichung achtet. In diesem Fall ist die Korrelation auch perfekt, nur eben in die entgegengesetzte Richtung, was zur Folge hat, dass diese Korrelation den Wert \\(r(M,H) = -1\\) zeigt. Interessant und der Praxis am ehesten entsprechend, sind jedoch Fälle, in denen zwei Variablen nur teilweise Gemeinsamkeiten aufweisen. Im folgenden Beispiel wäre Abbildung 3: Hund und Mensch bewegen sich zum Teil unabhängig, zum Teil aber auch synchron. Dies entspricht dann einer Kovarianz, bzw. Korrelation die irgendwo zwischen \\(r \\in [-1, 1]\\) liegt (im Beispiel ist \\(r(M,H) = 0.5\\) und somit \\(r^2 = 0.25\\)). Die Korrelation liegt in diesem Beispiel bei \\(r(M,H) = 0.5\\). Daraus lässt sich auch nochmals eine sehr wichtige Erkenntnis bezüglich der geteilten Varianz der beiden Variablen festhalten: Bei einer Korrelation von \\(r(x,y) = 0.5\\) entspricht der Determinationskoeffizient \\(r^2(x,y) = 0.25\\). In Prozent ausgedrückt, werden als 25% der Variabilität einer Variablen (z.B. Hund) durch die Variable Mensch erklärt. In welchen Abschnitten der Daten diese gemeinsame Variablität auftritt, lässt sich durch den \\(r\\) nicht bestimmen. Diese Feststellung führt uns aber zu einer weiteren Betrachtung von Variablitäten: Abbildung 4: Hund und Mensch scheinen sich wieder synchron, aber in gegenseitiger Richtung zu bewegen. Man würde also eine negative und hohe Korrelation erwarten. Interressant ist jedoch die Beobachtung, dass ein Versatz der Beobachtungen um eine Einheit zu einem hohen positiven Zusammenhang führen würde! Würde man davon ausgehen, dass sich der Mensch und Hund bei jedem Messzeitpunkt (1 bis 6) jeweils auf der gleichen Höhe befunden haben, dann wird man eine hohe negative Korrelation erhalten. Nimmt man jedoch an, dass der Mensch zum Messzeitpunkt (MZP) 1, der Hund aber bereits auf MZP 2 war, dann verschiebt sich die Spur des Hundes einfach um einen MZP nach oben! Korreliert man nun diese beiden Beobachtungen, würde sich eine nahezu perfekte positive Korrelation ergeben! Durch schrittweises Verschieben der Werte einer Variablen um eine Einheit (\\(\\tau_i\\)) mit anschließender Berechnung der Korrelationskoeffizienten (\\(r_{\\tau_i}(x,y)\\)), erhält man in Abhängigkeit von der Anzahl der Verschiebungen (\\(i \\in [0, N-1]\\)) maximal \\(N\\) neue Korrelatinskoeffizienten. Man bezeichnet diese Art der Korrelationsberechnung als Kreuzkorrelation. Für das Beispiel ergibt sich eine normale Korrelation von \\(r(M,H)=\\) -1. Die Korrelationen berechnet nach dem Versatzprinzip ergeben folgendes Bild: Die Verschiebung \\(\\tau\\) wurde in diesem Beispiel mit \\(i = 4\\) angegeben, d.h. es wurden die Werte der Variablen Hund um jeweils vier Schritte nach links und vier Schritte nach rechts verschoben. Bei jeder Verschiebung wurde die Korrelation berechnet (im Graphen ist die Verschiebung mit Lag auf der x-Achse angegeben). Auf der y-Achse wird der entsprechende Korrelationskoeffient angezeigt. Tau CrossCorr -4 -0.4253 -3 0.431 -2 -0.3678 -1 0.6609 0 -1 1 0.6609 2 -0.3678 3 0.431 4 -0.4253 Die Werte der Tabelle zeigen nochmals den krassen Wechsel der Korrelation zwischen den Werte \\(\\tau = 0\\) (also keiner Verschiebung) und \\(\\tau = 1\\). Werden die Werte um nur einen Beobachtungspunkt verschoben, ändert sich die Korrelation von einer perfekt negativen, zu einer sehr hohen positiven Korrelation! Eine weitere wichtige Eigenschaft die mit Hilfe dieser Vorgehensweise geprüft werden kann, ist die der sogenannten Autokorrelation. Diese funktioniert im Prinzip wie die eben beschriebene Kreuzkorrelation, mit dem Unterschied, dass eine Variable mit verschobenen “Eigenversionen” korreliert wird. Folgendes Beispiel zeigt das Ergebnis für die Variable Mensch unseres Beispiels: Die Verschiebung \\(\\tau\\) wurde in diesem Beispiel mit \\(i = 4\\) angegeben, d.h. es wurden die Werte der Variablen Mensch ebenfalls schrittweise in eine Richtung verschoben. Bei jeder Verschiebung wurde die Korrelation berechnet (im Graphen ist die Verschiebung mit Lag auf der \\(x\\)-Achse angegeben). Auf der \\(y\\)-Achse wird der entsprechende Korrelationskoeffient angezeigt. Tau CrossCorr 0 1 1 -0.6609 2 0.3678 3 -0.431 4 0.4253 Die perfekte positive Korrelation bei einer Verschiebung um den Wert \\(\\tau = 0\\) ist bei der Autokorrelation trivial, da es sich ja um einen direkten Vergleich der Variablen mit sich selbst handelt. Bei Lag = 1 wird jedoch ersichtlich, dass sich die Korrelation ändert (auf \\(r = -0.66\\)), springt dann wieder auf \\(r = +0.37\\) usw. Es ist zu beachten, dass dieser Datensatz nur zu Demonstrationszwecken erzeugt wurde. Eine inhaltliche Interpretation wäre im gegebenen Fall nicht angebracht. Nichts desto trotz sollte durch diese Beispiel gezeigt werden, dass sowohl die Kreuzkorrelation als auch die Autokorrelation vor allem in der Zeitreihenanalyse (und damit auch bei Längsschnittstudien) wichtige Erkenntnisse über die betrachteten Variablen liefern können. Vor allem kann eine vorliegende Autokorrelation bei der MLR zu beträchtlichen Einschränkungen der Gültigkeit einen Modells beitragen. Bei den MLR-Methoden werden wir noch über Möglichkeiten sprechen, Autokorrelationen auf statitische Signifikanz zu prüfen (Stichwort: Durbin-Watson). "],
["korrelationen.html", "Korrelationen Pearson Produkt Moment Korrelation Kausalität Partial- Semipartialkorrelation Korrelationstechniken", " Korrelationen Korrelationen sind ein Maß für den statistischen Zusammenhang zweier Datenreihen. Ein Korrelationsmaß impliziert daher auch stochastische Abhängigkeit - ohne jedoch auf kausale Zusammenhänge schließen zu können. Korrelationen werden i.A. der deskriptiven Statistik zugeordnet. Durch eine Reihe von Verfahren, wie z.B. partielle Korrelation, multiple Korrelation oder Faktorenanalyse, kann die einfache Korrelation zweier Variablen auf Beziehungen zwischen zwei Variablen unter Berücksichtigung des Einflusses weiterer Variablen werden. Korrelationen sind ein unverzichtbares Werkzeug für viele Forschungsgebiete und stehen häufig am Beginn jeder weiteren Datenanalyse, wie z.B.: multiple Regression Faktorenanalyse Clusteranalyse Mediator- und Moderator-Analyse Pearson Produkt Moment Korrelation Die häufigst verwendete Form der Korrelationsberechnung ist die Pearson-Produkt-Moment Korrelation. Bei dieser Methode wird die Beziehung zwischen zwei metrische Variablen (bzw. eine metrische und eine dichotome Variable) als Kennzahl mit dem Wertebereich \\(r \\in [-1,1]\\) berechnet. Die Berechnung einer Korrelation ist für sich gesehen an keine Voraussetzungen gebunden. Hingegen fordern eine sinnvolle Interpretationen der berechneten Kennwerte und vor allem die statistischen Tests von Korrelationskoeffizienten folgende inhaltliche und formale Überlegungen: Skalenniveau: der Korrelationskoeffizient liefert sinnvoll interpretierbare Ergebnisse wenn die Variablen mindestens intervallskaliert sind (oder für eine intervallskalierte und eine dichotome Variable1). Endliche Varianz (und Kovarianz): bei Erhöhung des Stichprobenumfangs darf sich die Variabilität nicht immer weiter erhöhen, sondern sollte sich stabilisieren. Bei Variablen, die bivariat normalverteilt sind, ist diese Voraussetzung automatisch gegeben. Der Korrelationskoeffizient ist damit auch gleichzeitig der Maximum-Likelyhood Schäzter des Korrelationskoeffizienten in der Grundgesamtheit (asymptotisch erwartungstreu und effizient). Abbildung 5: Endliche Varianz2 Linearität: die Korrelation ist ein Maß für lineare Abhängigkeit. Abweichungen der Daten von dieser Linearitätsannahme führen zu einer mehr oder weniger starken Verzerrung des Korrelationskoeffizienten, wie in den nachfolgenden Beispielen gezeigt wird: Abbildung 6: Linearität und Korrelation Vor allem zur Prüfung der Signifikanz einer Korrelation sollem man weitere Voraussetzungen überprüfen: Normalverteilung: Korrelation berechnen sich aus dem Kreuzprodukt von z-standardisierten Werten zweier Variablen. Für diese Berechnung wird der Mittelwert als zentraler Kennwert verwendet, welcher nur dann ein “sinnvoller” Kennwert für die Daten ist, wenn diese zumindest symmetrisch und im besten Fall normalverteilt sind. Homoskedastizität: bedeutet gleichmäßige Streuung der Daten zweier (exogene und endogene) Variablen. Sind die exogene und die endogene Variable3 nicht mehr identisch verteilt, d.h. sie ändern ihre Variablität mit zu/abnehmenden Werten einer Variablen, spricht man von Herteroskedastizität. Das hat zur Folge hat, dass die KQ4-Schätzer nicht mehr effizient sind und der Standardfehler der Koeffizienten verzerrt und nicht konsistent wird. Abbildung 7: Variablität(einschränkung) und Korrelation KEINE Ausreißer: der Korrelationskoeffizient ist nicht robust gegenüber Ausreißern. Dies bedeutet, dass Ausreißer den Korrelationskoeffizienten sowohl künstlich erhöhen als auch künstlich senken können. Abbildung 8: Einfluss von Ausreißer bei linearer Modellbildung KEINE Kluster: es kann vorkommen, dass zwei oder mehr Gruppen eine Korrelation zeigen, die eigentlich getrennt untersucht werden müssten. Dieses Problem wird oft auch mittels partieller Korrelation umgangen, bei der mögliche Drittvariablen statistisch konstant gehalten werden. Abbildung 9: Kluster und deren Auswirkung bei linearer Modellierung Beispiel Pearson Korrelation Im folgenden, fiktiven Beispiel werden die Zusammenhänge von Klausurperformanz (EP), Intelligenz (IQ), Vorbereitungszeit (VZ) und Prüfungsangst (PA) korreliert. Der Code zum Laden der Daten sowie die Daten selbst sind in nachfolgender Ausgabe/Tabelle dargestellt: load(&quot;Daten/CorrBsp1.Rda&quot;) EP IQ VZ PA 74 109 16 117 67 96 18 122 72 106 13 108 66 89 12 97 63 93 14 98 67 102 15 106 Aufgabe 1 Kopiere den obigen Code zum Laden der Daten in eine R-Script-Datei. Führen nun folgende Aufgaben aus: Ermittle mit einer geeigneten Funktion die Korrelationen und prüfe diese auch auf statistische Signifikanz. Zeichne einen Korrelationsplot mit dem Paket corrplot. Berechne die Teststärke der Korrelation \\(r(IQ, EP)\\) (Hinweis: verwende die Funktion pwr.r.test des Pakets pwr). Verwende diese Funktion (pwr.r.test) um für eine Korrelation \\(r(x,y) = 0.21\\) den optimalen Stichprobenumfang zu berechnen. Prüfe mit Hilfe der Funktion mvn aus dem Paket MVN die Voraussetzung der bivariaten Normalverteilung der Variablenpaare (EP,IQ), (EP, VZ) und (EP,PA). Berechne die durchschnittliche Korrelation von \\(r_1(EP,IQ)\\), \\(r_1(EP,VZ)\\) und \\(r_1(EP,PA)\\). Beachte, dass zur Berechnung von durchschnittlichen Korrelationswerten eine Fisher-Z-Transformation notwendig ist (Hinweis: verwende die fisherz() und fisherz2r() des Pakets psych). Prüfe, ob der Unterschied der Korrelationskoeffizienten \\(r(EP,IQ) = 0.47\\) und \\(r(EP,VZ) = 0.36\\) statistisch signifikant ist. Verwende die Funktion paired.r() aus dem Paket psych. Lösung Aufgabe 1 Kausalität Eine relevante (statistisch signifikante) Korrelation liefert keinen Beleg für die Kausalität. Vor allem in der Medizin und Psychologie suchen Forscher nach Kriterien für Kausalität. Es existieren mehrere Ansätze zur Erklärung der Ursächlichkeit einer Korrelation (siehe z.B. die 9 Bradford-Hill-Kriterien). Partial- Semipartialkorrelation Die partielle Korrelation ist die bivariate Korrelation zweier Variablen, welche mittels linearer Regression vom Einfluss einer Drittvariablen bereinigt wurden. Eine Semipartialkorrelation ist ein Zusammenhang zwischen einer residualisierten und einer nicht-residualisierten Variable. Abbildung 10: Partial und Semipartialkorrelation in einem Venn-Diagramm dargestellt Beispiel Partial- Semipartialkorrelation Folgendes Beispiel verdeutlicht die Wirkungsweise einer Partial- und Semipartialkorrelation. Kopier den folgenden Code in ein R-Script und führe diesen dann aus. Diskutiere die Ergebnisse. examData &lt;- read.delim(&quot;Daten/Exam Anxiety.dat&quot;, header = TRUE) examData2 &lt;- examData[, c(&quot;Exam&quot;, &quot;Anxiety&quot;, &quot;Revise&quot;)] # Normale Korrelation pander::pander(round(cor(examData2),2)) # Partielle Korrelation # library(ppcor) pander::pander(round(ppcor::pcor(examData2)$estimate,2)) # Partialkorrelation mit Linearen Modell Mod1 &lt;- lm(Exam ~ Revise, data = examData2) Res_Exam_Rev &lt;- residuals(Mod1) Mod2 &lt;- lm(Anxiety ~ Revise, data = examData2) Res_Anx_Rev &lt;- residuals(Mod2) pr_Exam_Anx_Rev &lt;- round(cor(Res_Exam_Rev, Res_Anx_Rev), 2) In diesem Code wurde zur Veranschaulichung der Wirkungsweise einer Partial/Semipartialkorrelation eine lineare Regression verwendet. Was dabei genau passiert sei durch nachfolgende Abbildung nochmals veranschaulicht: Abbildung 11: Partialkorrelation als lineares Regressionsmodell. Für die Beziehung Examperformance und Exam Anxiety soll der Effekt von Revisiotime berücksichtigt werden. Die roten Linien entsprechen den Residuen der Regression Revisiontime mit Exam Performance. Die blauen den Residuen der Regression Revisiontime mit Exam Anxiety. Der linke obere Graph stellt die Beziehung von Anxiety und Examperfomance bereinigt von Revisiontime dar. Details siehe nachfolgendemn Text. Examperformance wird durch Revisiontime vorhergesagt. Die Residuen sind jener Anteil an Variabilität der Examperformanz, der nicht durch Revsiontime vorhergesagt werden können5. Diese über die durch Revisiontime erklärbare Variabilität von Examperformance kann zurückgeführt werden auf: andere erklärende Merkmale, bzw. Messfehler Anxiety wird durch Revisiontime vorhergesagt. Auch hier gilt wieder, dass die Residuen der Variabilität von Anxiete, bereinigt von Revisiontime entsprechen. Die Korrelation der Residuen entspricht nun genau der Partialkorrelation \\(r_{Y1\\cdot2}\\) Bei der Semipartialkorrelation bereinigt man nun nicht beide Variablen, sonder eben nur einen Teil (z.B. wird nur die Anxiety von Revisiontime bereiningt). Kopiere den nachfolgenden Code in ein R-Script und führe diesen aus. Diskutiere die Ergebnisse! # Semipartielle Korrelation pander::pander(round(ppcor::spcor(examData2)$estimate,2)) # Semipartialkorrelation mit Linearen Modell sr_Exam_Anx_Rev &lt;- round(cor(examData2$Exam, Res_Anx_Rev), 2) Korrelationstechniken Neben dem Pearson-Produkt-Moment-Korrelationskoeffizienten \\(r\\) existieren noch etliche weitere Korrelationskoeffizienten und Zusammenhangsmaße. Die meisten hiervon sind Sonderfälle der Pearson-Produkt-Moment-Korrelation. Nachfolgende Tabelle zeigt, wann welcher Koeffizient berechnet werden soll. Die Verwendung unterschiedlicher Korrelationsberechnungen ist i.A. abhängig vom Skalenniveau der beteiligten Variablen. Abbildung 12: verschiedene Korrelationskoeffizienten Spearman und Kendall Für die Berechnung des Pearson-Korrelationskoeffizienten (\\(r\\)) ist das Vorliegen von kontinuierlichen Variablen erforderlich. Bei ordinalskalierten Daten wird eine der folgenden Rangkorrelation berechnet: Spearman \\(r_s\\): Spearman-Rangkorrelation setzt voraus, dass Ränge gleichabständig sind6 und keine Ausreißer vorliegen. Kendall \\(\\tau\\): Ränge müssen nicht gleichabständig sein und Ausreißer beeinflussen diesen Korrelationskoeffizienten weit weniger als z.B. den den \\(r_s\\). Bei den Kendall-Koeffizienten unterscheidet man noch drei unterschiedliche Maße7: Kendalls \\(\\tau_a\\): Rangbindungen werden nicht berücksichtigt. Kendalls \\(\\tau_b\\): Rangbindungen werden berücksichtigt. Kendalls \\(\\tau_c\\): für nicht quadratische Kontingeztafeln. Zur Veranschaulichung der verschiedenen rangbasierten Korrelationsmaße sind folgende Aufgaben zu bearbeiten: Berechne zuerst nochmal die Pearson-Korrelation \\(r(EP,IQ)\\) des bereits geladenen Datensatzes und rechne dann eine Spearman Korrelation. Verwende nun die Funktion cor() des Basispakets. Vergleiche die Ergebnisse! Vererwende die Funktion rank() um den Variablen EP und IQ Ränge zuzuordnen. Speichere die Ergebnisse in EP_Ranks und IQ_Ranks und berechnen Sie anschließend eine Pearson-Korrelation. Vergleiche die Ergebnisse mit dem vorherigen Pearson-\\(r\\). Lösung Aufgabe 2 Biseriale Korrelation Biseriale Korrelationen kommen zur Anwendung, wenn ein Merkmal Intervall- oder Ordinalskaliert und das zweite Merkmal dichotom Nominalskaliert ist. Für das Nominalskalierte Merkmal unterscheidet man noch zwischen: Echt dichotome Variable: natürlich vorkommende Gruppenteilung wie z.B. wahr/falsch, männlich/weiblich, etc. Der Zusammenhang einer solchen mit einer intervallskalierten Variablen wird durch die punktbiseriale Korrelation beschrieben. Künstlich dichotome Variable: wird eine kontinuierliche Variable in zwei Gruppen aufgeteilt, wie z.B. zwei Altersgruppen (jung, alt), oder hohe Leistungsfähigkeit vs. niedrige Leistungsfähigkeit, etc., dann spricht man von einer künstlich dichotomen Variablen. Zusammenhänge dieser mit einer intervallskalierten Variablen werden durch die biseriale Korrelation beschrieben. Kopier den folgenden Code in dein R-Script und bearbeite folgende Aufgabenstellungen: Verwende die Funktion dicho() des Pakets sjmisc um alle Variablen über den Median zu dichotomisieren (Hinweise: ersetze die XXX im Code mit den entsprechenden Werten). Berechne die biseriale Korrelation der Variablen IQ und der Exam-Performance-Gruppe (EP_Grp). # Zuerst wird die Examensperformanz Ã¼ber den Median in zwei Gruppen geteilt # library(sjmisc) DF_Biserial &lt;- DF_Korr[order(EP), ] DF_Biserial &lt;- sjmisc::dicho(XXX, dich.by = &quot;XXX&quot;, as.num = FALSE, var.label = &quot;Grp&quot;, val.labels = c(&quot;low&quot;, &quot;high&quot;), append = TRUE, suffix = &quot;_Grp&quot;) biserial(x = XXX, y = XXX) Phi-Koeffizient Korrelationen zwischen echt-dichotomen Variablen (männlich/weiblich, etc.) können mit dem Phi-Koeffizienten berechnet werden. Um den Phi-Koeffizienten zu berechnen, werden Häufigkeiten in Form einer Vier-Felder-Tafel benötigt. Abbildung 13: Beispiel und Berechnung des Phi-Koeffizienten Folgendes einfaches Beispiel zeigt die Berechnung des Phi-Koeffizienten sowie dessen Äquivalenz mit einer Pearson-Korrelation: Geschlecht &lt;- c(1, 1, 0, 0, 1, 0, 1, 1, 1) Bestanden &lt;- c(1, 1, 1, 0, 0, 0, 1, 1, 1) VFT &lt;- table(Geschlecht, Bestanden) pander::pander(VFT) cor(Geschlecht, Bestanden) phi(VFT) CST &lt;- chisq.test(VFT, correct = FALSE) pander::pander(CST) qchisq(p=.95,df=1) # kritischer Chi-Square-Wert bei einem Freiheitsgrad und Alpha = 5% Die Anzahl der Freiheitsgrade beträgt in diesem Fall immer eins, da wir es mit zwei dichotomen Merkmalen zu tun haben. Tetrachorische Korrelation Soll der Zusammenhang zwischen zwei künstlich-dichotomen Variablen berechnet werden, die aus stetigen, normalverteilten latente Variablen abgeleitet wurden (z.B. Intelligenz und Examperformanz in Statistik), verwendet man die tetrachorische Korrelation. Auf Details zur Berechnung der Kenngröße wird hier verzichtet. Grundlage ist wiederum eine Vier-Felder-Tafel (wie beim Phi-Koeffizienten), wobei die tetrachorische Korrelation nicht so stark von der Randverteilung der Vier-Felder-Tafel abhängt. Zu beachten ist jedoch, dass die Zellbesetzung von b und c nicht 0 sein darf! Nachfolgendes Beispiel sollte die Anwendung der tetrachorischen Korrelation verdeutlichen. Lade dazu den folgenden Code und führe diesen Zeilenweise aus. Diskutiere die Ergebnisse! # library (psych) load(&quot;Daten/TetraCorrBsp.Rda&quot;) TCC_Res &lt;- tetrachoric(DF_TCC) pander(TCC_Res$rho) Polychorische Korrelation Um Korrelationen zwischen ordinalen Daten zu beschreiben, verwendet man die polychorische Korrelation. Dabei schätzt man die Korrelation zwischen zwei (ordinalen) Merkmalen, die in mehr als zwei geordnete Kategorien unterteilt sind. Die Berechnung ist überaus komplex und wird hier nicht dargestellt. Polychorische Korrelationen werden unter anderem verwendet, um konfirmatorische Faktorenanalysen mit ordinalen Daten zu berechnen. Es ist mit Programmen wie R, AMOS, LISREL oder MPlus auch möglich, exploratorische Faktorenanalysen mit polychorischen Korrelationen durchzuführen. dieser Spezialfall ist unter biserialer, bzw. punktbiserialer Korrelation bekannt.↩ die Abbildungen wurden der Website Matheguru entnommen↩ eine exogene Variable ist eine erklärende Variable, die mit der Störgröße unkorreliert ist (sogenannte Exogenität). Eine endogene Variable in einem multiplen Regressionsmodell ist eine erklärende Variable, die entweder aufgrund einer ausgelassenen Variablen, eines Messfehlers oder wegen Simulatanität mit der Störgröße korreliert ist (sogenannte Endogenität).↩ KQ steht für kleinste Quadrate (auch MLS - Minimum Least Square, oder OLS - Ordinary Least Square) und ist eine einfache Schätzung über minimierte quadradische Abstände der Residuen (Fehler) zu einem Modell (Mittelwert, Gerade, etc.)↩ anderenfalls würden ja alle beobachteten Werte auf der Gerade liegen!↩ diese Voraussetzung ist eher selten erfüllt. Sie ist gleichzusetzen mit der Annahme, dass in einem Skirennen der erste, zweite, dritte, etc. Platz genaus die gleichen Zeitabstände aufweisen. Ist diese nicht gegeben, sollte Kendalls \\(\\tau\\) verwendet werden.↩ Details zu den unterschiedlichen Kendalls-\\(\\tau\\) sind der Literatur zu entnehmen. Weitere Betrachtungen beziehen sich auf das Kendalls-\\(\\tau_b\\)↩ "],
["losungen.html", "Lösungen Aufgabe_1 Aufgabe_2 Aufgabe_3", " Lösungen Aufgabe_1 # library(Hmisc) fÃ¼r Hmisc::rcorr # library(corrplot) fÃ¼r corrplot # library(pwr) # 1. Ermitteln Sie mit einer geeigneten Funktion die Korrelationen und prÃ¼fen Sie # diese auch auf statistische Signifikanz. CorRes &lt;- Hmisc::rcorr(as.matrix(DF_Korr), type=&quot;pearson&quot;) # type can be pearson or spearman pander::pander(round(CorRes$r, 2)) pander::pander(round(CorRes$P , 2)) # 2. Zeichnen Sie einen Korrelationsplot mit dem Paket *corrplot*. corrplot::corrplot(cor(DF_Korr), type=&quot;upper&quot;, method = &quot;ellipse&quot;) # 3. Berechnen Sie die TeststÃ¤rke der Korrelation $r(IQ, EP)$ # (Hinweis: verwenden Sie die Funktion *pwr::pwr.r.test* des Pakets *pwr*). N &lt;- dim(DF_Korr)[1] PwrA &lt;- pwr::pwr.r.test(n = N, r = 0.47, sig.level = 0.05, alternative = &#39;two.sided&#39;) pander::pander(data.frame(Kennwerte = unlist(PwrA))) # 4. Verwenden diese Funktion (*pwr::pwr.r.test*) um fÃ¼r eine Korrelation $r(x,y) = 0.21$ # den optimalen Stichprobenumfang zu berechnen. OptN &lt;- pwr::pwr.r.test(r = 0.21, sig.level = 0.05, power = 0.95, alternative = &#39;greater&#39;) pander::pander(data.frame(Kennwerte = unlist(OptN))) # 5. PrÃ¼fen Sie mit Hilfe der Funktion *mvn* aus dem Paket *MVN* # die Voraussetzung der bivariaten Normalverteilung der # Variablenpaare (EP,IQ), (EP, VZ) und (EP,PA). # library(MVN) # mvn(DF_Korr[, c(&quot;EP&quot;,&quot;IQ&quot;)], multivariatePlot = &quot;persp&quot;) # mvn(DF_Korr[, c(&quot;EP&quot;,&quot;VZ&quot;)], multivariatePlot = &quot;persp&quot;) # mvn(DF_Korr[, c(&quot;EP&quot;,&quot;PA&quot;)], multivariatePlot = &quot;persp&quot;) # 6. Berechnen Sie die durchschnittliche Korrelation von $r_1(EP,IQ)$, $r_1(EP,VZ)$ und $r_1(EP,PA)$. round(fisherz2r(mean(c(fisherz(.47), fisherz(.36), fisherz(-.25)))), 2) # 7. PrÃ¼fen Sie, on der Unterschied der Korrelationskoeffizienten $r(EP,IQ) = 0.47$ und $r(EP,VZ) = 0.36$ # statistisch signifikant ist. Verwenden Sie die Funktion *psych::paired.r()* aus dem Paket *psych* # library(psych) psych::paired.r(xy = .47, xz = .36, n = N, twotailed = TRUE) zurück zu Aufgabe Aufgabe_2 # library(Hmisc) # 1. Berechnen Sie zuerst nochmal die Pearson-Korrelation $r(EQ,IQ)$ des bereits geladenen Datensatzes # und rechnen Sie dann eine Spearman Korrelation. Verwenden Sie nun die Funktion cor() des Basispakets. # Vergleichen Sie die Ergebnisse! EP &lt;- DF_Korr$EP IQ &lt;- DF_Korr$IQ CorPearson &lt;- round(cor(EP, IQ, method = &quot;pearson&quot;), 2) CorSpearman &lt;- round(cor(EP, IQ, method = &quot;spearman&quot;), 2) CorKendall &lt;- round(cor(EP, IQ, method = &quot;kendall&quot;), 2) pander::pander(data.frame(Pearson = CorPearson, Spearman = CorSpearman, Kendall = CorKendall)) # Alternativ kann auch cor.test() verwendet werden, dabei werden die Tests auf # Signigikanz gleich mitgerechnet. # cor.test(x = EP, # y = IQ, # alternative = &#39;two.sided&#39;, # method = &#39;pearson&#39;) # cor.test(x = EP, # y = IQ, # alternative = &#39;two.sided&#39;, # method = &#39;spearman&#39;) # cor.test(x = EP, # y = IQ, # alternative = &#39;two.sided&#39;, # method = &#39;kendall&#39;) # Bemerkung: cor.test() mit Kendall bringt Warnung bezÃ¼glich der Rangbindungen. # Alternativ kann man daher die Funktion Kendall() des Paketes Kendal verwenden: # library(Kendall) # Kendall(x = EP, # y = IQ) # 2. Verwenden Sie die Funktion rank() um den Variablen EP und IQ RÃ¤nge zuzuordnen. # Speichern Sie die Ergebnisse in EP_Ranks und IQ_Ranks und berechnen Sie anschlieÃŸend # eine Pearson-Korrelation. Vergleichen Sie die Ergebnisse mit dem vorherigen Pearson-r. EP_Ranks &lt;- rank(EP, na.last = TRUE, ties.method = c(&quot;average&quot;)) IQ_Ranks &lt;- rank(IQ, na.last = TRUE, ties.method = c(&quot;average&quot;)) round(cor(EP_Ranks, IQ_Ranks, method = &quot;pearson&quot;), 2) zurück zu Aufgabe Aufgabe_3 # Zuerst wird die Examensperformanz Ã¼ber den Median in zwei Gruppen geteilt # library(sjmisc) DF_Biserial &lt;- DF_Korr[order(EP), ] DF_Biserial &lt;- sjmisc::dicho(DF_Biserial, dich.by = &quot;median&quot;, as.num = FALSE, var.label = &quot;Grp&quot;, val.labels = c(&quot;low&quot;, &quot;high&quot;), append = TRUE, suffix = &quot;_Grp&quot;) IQ &lt;- DF_Biserial$IQ biserial(x = IQ, y = DF_Biserial$EP_Grp) zurück zu Aufgabe rm(list = ls()) graphics.off() if (!require(&quot;pacman&quot;)) install.packages(&quot;pacman&quot;) pacman::p_load(car, DAAG, ggplot2, pander, ppcor, mosaicData, reshape2, rockchalk) "],
["multiple-regression.html", "Multiple Regression Definition Modellvergleich Aufgabe MLR 1 Wahl relevanter Prädiktoren Sequentielle Modellbildung Modellvergleiche Voraussetzungen MLR", " Multiple Regression Regressionsanalysen sind statistische Analyseverfahren, die zum Ziel haben, Beziehungen zwischen einer abhängigen und einer oder mehreren unabhängigen Variablen zu modellieren. Sie werden insbesondere verwendet, wenn Zusammenhänge quantitativ zu beschreiben oder Werte der abhängigen Variablen zu prognostizieren sind. In der Statistik ist die multiple lineare Regression (auch mehrfache lineare Regression (MLR) oder lineare Mehrfachregression genannt), ein Spezialfall des allgemeinen Konzepts der Regressionsanalyse. Die Multiple lineare Regression ist ein statistisches Verfahren, mit dem versucht wird, eine beobachtete abhängige Variable durch mehrere unabhängige Variablen zu erklären. Die multiple lineare Regression stellt eine Verallgemeinerung der einfachen linearen Regression dar. Das Beiwort „linear“ bedeutet, dass die abhängige Variable als eine Linearkombination (nicht notwendigerweise) linearer Funktionen der unabhängigen Variablen modelliert wird (siehe Wikipedia). Definition Die formale Definition eines multiplen linearen Modells ist: \\[\\begin{equation} y_i = b_0 + b_1 \\cdot x_{1i} + \\cdots + b_k \\cdot x_{ki} + \\varepsilon_i \\tag{1} \\end{equation}\\] Die wesentlichen Parameter dieses Modells sind: Intercept \\(b_0\\): jener Wert den \\(y_i\\) einnimmt, wenn \\(x_{ji} = 0\\) ist (mit \\(i \\in [1,N]\\), \\(N=\\) Anzahl der Beobachtungen und \\(j \\in [1,k]\\), \\(k=\\) Anzahl der Prädiktoren). Steigung \\(b_i\\): die Zunahme von \\(y_i\\), wenn \\(x_{ji}\\) sich um eine Einheit erhöht, bei gleichzeitigem Konstanthalten der restlichen Prädiktorwerte \\(x_{mi}\\) (mit \\(m [1,k]\\) und \\(m \\ne j\\))! Des Weiteren berücksichtigt dieses Modell einen Fehler (\\(\\varepsilon_i\\)). Betrachtet man das multiple Modell isoliert (also ohne Fehlerterm), ist folgende Schreibweise üblich: \\[\\begin{equation} \\hat{y}_i = b_0 + b_1 \\cdot x_{1i} + \\cdots + b_k \\cdot x_{ki} \\tag{2} \\end{equation}\\] Zur Veranschaulichung betrachten wir anhand der folgenden Beispieldaten folgendes Modell mit zwei Prädiktoren: \\[\\begin{eqnarray*} \\hat{wage}_i = b_0 + b_1 \\cdot educ_{i} + b_2 \\cdot exper_{i} \\tag{3} \\end{eqnarray*}\\] Es sollte als das Einkommen (\\(wage_i\\)) durch den Ausbildungsstand (\\(educ_i\\)) und die Arbeitserfahrung (\\(exper_i\\)) vorhergesagt werden. Die verwendeten Daten stammen vom Paket DAAG (Data from the 1985 Current Population Survey) und werden als Datenframe (CPS85) automatisch mit dem Laden des Pakets zur Verfügung gestellt. Erstelle ein neues R-Script, in welches in den ersten Zeilen der Anfangs erwähnte Codeteil zum Laden der Pakete kopiert werden soll. Anschließend kopier den nachfolgenden Code und führe diesen aus. # library(mosaicData) fuer CPS85 model_1 &lt;- lm(wage ~ educ, data = CPS85) model_2 &lt;- lm(wage ~ educ + exper, data = CPS85) Det_model_2 &lt;- pander::pander(summary(model_2)) rockchalk::plotPlane(model = model_2, plotx1 = &quot;educ&quot;, plotx2 = &quot;exper&quot;) Der Koeffizient \\(b_2\\) entspricht der Zunahme des Gehaltes \\(\\hat{y}_i\\) wenn sich die Erfahrung \\(x_{2i}\\) um eine Einheit erhöht und die Ausbildung \\(x_{1i}\\) konstant gehalten wird. In nachfolgernder Tabelle sind die Werte der Vorhersagen des Modells für den vorliegenden Datensatz auszugsweise dargestellt (übernimm den Code in dein R-Script und führe diesen aus): MinExp &lt;- min(CPS85$exper) MaxExp &lt;- max(CPS85$exper) RowSeq &lt;- seq(from = 1, to = MaxExp, by = 1) educVon &lt;- 10 educBis &lt;- 18 AnzCols &lt;- educBis - educVon + 1 Predicted &lt;- matrix(NA, nrow = MaxExp, ncol = AnzCols) for (i in seq(from = 1, to = MaxExp, by = 1)) { new_input &lt;- data.frame(educ = educVon:educBis, exper = i) Predicted[i,] &lt;- predict(model_2, newdata = new_input) } Predicted &lt;- data.frame(seq(from = 1, to = MaxExp, by = 1), Predicted) colnames(Predicted) &lt;- c(&quot;Exp&quot;, &quot;Edu10&quot;, &quot;Edu11&quot;,&quot;Edu12&quot;, &quot;Edu13&quot;, &quot;Edu14&quot;,&quot;Edu15&quot;, &quot;Edu16&quot;,&quot;Edu17&quot;, &quot;Edu18&quot;) TabRows2Disp &lt;- c(1:3, 53:55) Predicted2Disp &lt;- Predicted[TabRows2Disp,] row.names(Predicted2Disp) &lt;- NULL pander::pander(Predicted2Disp, style = &quot;rmarkdown&quot;) Exp Edu10 Edu11 Edu12 Edu13 Edu14 Edu15 Edu16 Edu17 Edu18 1 4.46 5.386 6.312 7.238 8.164 9.09 10.02 10.94 11.87 2 4.565 5.491 6.417 7.343 8.269 9.195 10.12 11.05 11.97 3 4.671 5.597 6.522 7.448 8.374 9.3 10.23 11.15 12.08 53 9.927 10.85 11.78 12.71 13.63 14.56 15.48 16.41 17.33 54 10.03 10.96 11.88 12.81 13.74 14.66 15.59 16.51 17.44 55 10.14 11.06 11.99 12.92 13.84 14.77 15.69 16.62 17.55 # library(reshape2) fuer melt # library(ggplot) fuer Plots CPS852Disp &lt;- reshape2::melt(Predicted, id.vars = &quot;Exp&quot;, measure.vars = c(&quot;Edu10&quot;, &quot;Edu11&quot;, &quot;Edu12&quot;, &quot;Edu13&quot;, &quot;Edu14&quot;,&quot;Edu15&quot;, &quot;Edu16&quot;, &quot;Edu17&quot;, &quot;Edu18&quot;)) CPS852Disp$Exp &lt;- rep(1:55, 9) colnames(CPS852Disp) &lt;- c(&quot;Exp&quot;, &quot;Edu&quot;, &quot;WagePred&quot;) p &lt;- ggplot(CPS852Disp, aes(x = Exp, y = WagePred, color = Edu)) + geom_line() + theme_bw() print(p, comment = FALSE) Modellvergleich Ein Modell sollte die Wirklichkeit mit wenigen Parametern, aber in bestmöglicher Genauigkeit abbilden. Bei der Erstellung eines Modells werden aufgrund einer Stichprobe aus der Grundgesamtheit die Modellparameter (\\(b\\)’s) bestimmt. Um festzustellen, inwieweit ein Modell brauchbare Vorhersagen liefert, sollte man das Modell evaluieren. In den vorangegangen Beispielen wurden zwei Modelle (model_1 und model_2) erstellt. Der Vergleich der Modelle ist über den Fehler (Residuen) des jeweiligen Modells möglich. Je kleiner der Fehler, desto besser bildet das Modell die beobachteten Werte ab. Im Idealfall (\\(\\varepsilon = 0\\)), würden alle beobachteten Werte gleich den vorhergesagten Werten sein und damit auf der Linie liegen. M &lt;- data.frame(wage = CPS85$wage, educ = CPS85$educ, exper = CPS85$exper) MV_Data &lt;- data.frame(educ = M$educ, exper = M$exper) MSE_Model1 &lt;- round(mean(resid(model_1)^2),2) # MSE_Model1 &lt;- mean((M$wage - predict(model_1, newdata = MV_Data))^2) StdResid &lt;- rstandard(model_1) # StdResid &lt;- (resid(model_1)-mean(resid(model_1)))/sd(resid(model_1)) MSE_Model2 &lt;- round(mean((M$wage - predict(model_2, newdata = MV_Data))^2),2) Der Modellvergleich der obigen Beispiele ergibt für das Modell 1 einen \\(MSE_1 =\\) 22.52 und für Modell 2 einen \\(MSE_2 =\\) 21.04. Bei diesen Ergebnis lässt sich zunächst nur feststellen, dass der \\(MSE_2\\) kleiner als der \\(MSE_1\\) ist. Ob diese Verringerung des \\(MSE\\) von statistischer und/oder praktischer Signifikanz ist, wird im folgenden noch genauer betrachtet. Mit einer einfachen ANOVA lässt sich nun auch die statistische Signifikanz der Änderungen im Fehler bei den verwendeten Modellen berechnen. Betrachten wir zunächst die statistische Änderung die Modell 1 im Vergleich zum Mittelwertsmodell erzielt: # ANOVA Tests auf signifikante Aenderungen model_1 vs Mittelwertsmodell # Berechnung der Quadratsummen fuer die Regression (educ) preds_1 &lt;- predict(model_1, newdata = CPS85) AnzPred &lt;- 2 # b_0 und b_1 SS_Regression_1 &lt;- sum((preds_1 - mean(preds_1))^2) Zdf_Regression_1 &lt;- AnzPred - 1 MSS_Regression_1 &lt;- round(SS_Regression_1 / Zdf_Regression_1, 2) # Berechnung der Quadratsummen des Fehlers (Residuals) Residuals_1 &lt;- CPS85$wage - preds_1 SS_Residuals_1 &lt;- sum(Residuals_1^2) Ndf_Residuals_1 &lt;- nrow(CPS85) - AnzPred MSS_Residuals_1 &lt;- round(SS_Residuals_1 / Ndf_Residuals_1, 2) # Berechnung der Teststatistik F_Wert &lt;- round(MSS_Regression_1 / MSS_Residuals_1, 2) # Berechnung der totalen Quadratsumme SS_Total_1 &lt;- sum((CPS85$wage - mean(CPS85$wage))^2) CPS85_Total &lt;- nrow(CPS85) - 1 # Vergleich mit den Ergebnissen der ANOVA pander::pander(anova(model_1)) Analysis of Variance Table Df Sum Sq Mean Sq F value Pr(&gt;F) educ 1 2053 2053 90.85 5.474e-20 Residuals 532 12023 22.6 NA NA Das Ergebnis zeigt uns, dass Modell 1 im Vergleich zum Mittelwertsmodell zu einer statistisch signifikanten Fehlerreduktion führt. Bei der händischen Berechnung der Prüfgrößen erhalten wir für die mittlere Quadratsumme der Regression (also der Varianz der Werte die durch das Modell vorhergesagt werden) einen Wert von \\(MSS_{Regression} =\\) 2053.29, welcher ident mit dem Wert der ANOVA-Tabelle ist. Die restlichen Kennwerte stimmen auch mit dem Ergebnis der ANOVA überein (\\(MSS_{Residual} =\\) 22.6, F(1,532) = 90.85). Wird das Modell 1 erweitert (auf Modell 2), stellt sich die Frage, ob diese Erweiterung im statistischen Sinn zu einer signifikanten Verbesserung führt. Bei diesem Vergleich wird nun die Änderung (Change Statistic) zwischen Modell 1 und Modell 2 auf Signifikanz geprüft. # ANOVA Tests auf signifikante Aenderungen model_1 vs model_2 (Aenderung signifikant?) pander::pander(anova(model_1, model_2)) Analysis of Variance Table Res.Df RSS Df Sum of Sq F Pr(&gt;F) 532 12023 NA NA NA NA 531 11233 1 790.6 37.37 1.893e-09 Zum Verständnis dieser Statistik greifen wir kurz zurück auf die verschiedenen Möglichkeiten der Berechnung von Korrelationskoeffizienten zurück. Diese sind: Pearson Korrelationskoeffizient (\\(r_{xy}\\)): entspricht der Kovarianz der \\(z\\)-transformierten Variablen. Partielle Korrealtionskoeffizient (\\(r_{xy \\cdot z}\\)): ist die bivariate Korrelation zweier Variablen, welche mittels linearer Regression vom Einfluss einer Drittvariablen bereinigt wurden. Semipartialkorrelation (\\(sr_{k \\cdot x_j}\\)): zwischen Kriterium und dem \\(j\\)-ten Prädiktor ergibt sich als Korrelation von \\(y\\) mit dem Residuum \\(x_j^*\\) der linearen Regression des \\(j\\)-ten Prädiktors auf den anderen Prädiktor. Mit anderen Worten, die Semipartialkorrelation gibt den alleinigen Beitrag eines Prädiktors \\(x_j\\) (bereinigt um die gemeinsamen Anteile mit den restlichen Prädiktoren) am Kriterium an. Das Quadrat dieses Koeffizienten wird unter anderm auch als Nützlichkeit des Prädiktors \\(U_k\\) bezeichnet und findet sich z.B. in SPSS als \\(R^2_{change}\\) wieder. Formal: \\(sr_{k \\cdot 12 \\cdots (k-1)}^2 = R_{y, 12 \\cdots k}^2 - R_{y, 12 \\cdots k-1}^2\\) Die Berechnung dieser Kennzahlen in R: # Korrelationen, Paritial- und Semipartialkorrelationen Korr_Data &lt;- data.frame(wage = M$wage, educ = M$educ, exper = M$exper) PearsonKorr &lt;- cor(Korr_Data) ModVgl_Korr &lt;- pander::pander(PearsonKorr) R2Change_mod_1 &lt;- PearsonKorr[2]^2 # Partial Korrelation zwischen &quot;wage&quot; und &quot;educ&quot; gegeben &quot;exper&quot; PartKorr_1 &lt;- ppcor::pcor.test(Korr_Data$wage, Korr_Data$educ, Korr_Data$exper) ModVgl_ParKorr_1 &lt;- pander::pander(PartKorr_1) # Partial Korrelation zwischen &quot;wage&quot; und &quot;exper&quot; gegeben &quot;educ&quot; PartKorr_2 &lt;- ppcor::pcor.test(Korr_Data$wage, Korr_Data$exper, Korr_Data$educ) ModVgl_ParKorr_2 &lt;- pander::pander(PartKorr_2) # Semi-Partial (part) Korrelation zwischen &quot;wage&quot; und &quot;educ&quot; gegeben &quot;exper&quot; SemiPartKorr_1 &lt;- ppcor::spcor.test(Korr_Data$wage, Korr_Data$educ, Korr_Data$exper) ModVgl_SemParKorr_1 &lt;- pander::pander(SemiPartKorr_1) # Semi-Partial (part) Korrelation zwischen &quot;wage&quot; und &quot;exper&quot; gegeben &quot;edu&quot; SemiPartKorr_2 &lt;- ppcor::spcor.test(Korr_Data$wage, Korr_Data$exper, Korr_Data$educ) ModVgl_SemParKorr_1 &lt;- pander::pander(SemiPartKorr_2) R2Change_mod_2 &lt;- round(SemiPartKorr_2$estimate^2,3) pander::pander(summary(model_2)) Estimate Std. Error t value Pr(&gt;|t|) (Intercept) -4.904 1.219 -4.024 6.564e-05 educ 0.926 0.0814 11.37 5.563e-27 exper 0.1051 0.0172 6.113 1.893e-09 Fitting linear model: wage ~ educ + exper Observations Residual Std. Error \\(R^2\\) Adjusted \\(R^2\\) 534 4.599 0.202 0.199 Im vorliegenden Beispiel sind daher die beiden Nützlichkeitsmaße \\(U_{educ}\\) = 0.146 und \\(U_{exper}\\) = 0.056 von Interesse. Ersteres bedeutet, dass die Varianzaufklärung aufgrund der Verwendung der Variablen educ 14.6% ist. Wird im Modell dann noch der Prädiktor exper aufgenommen, werden zusätzliche 5.6% an Varianz des Kriteriums wage erklärt. Insgesamt werden somit \\(R^2 = 0.202\\) oder 20.2% der Varianz des Kriteriums erklärt. Der Test (\\(t(531) = 11.37, p&lt; .001\\)) bestätigt für den Prädiktor educ, sowie (\\(t(531) = 6.11, p&lt;.001\\)) für den Prädiktor exper die statistische Signifikanz. Aufgabe MLR 1 Öffne ein neues R-Script und kopiere die bereits bekannte Kopfzeile in diese Datei. Speichere anschließend das Skript unter dem Namen SLR_Aufgabe2.R. Bearbeite nun folgende Aufgabenstellungen: Lade die Datei “Album Sales 2.dat” erstelle ein lineares Modell zur Vorhersage der Verkaufszahlen (sales) durch die Variable adverts. erstelle ein weiteres lineares Modell zur Vorhersage der Verkaufszahlen (sales) durch die Variable adverts, airplay und attract. Zeige die Ergebnisse des ersten Modells an. Zeige die Ergebnisse des zweiten Modells an. Vergleiche die beiden Modelle mit einer ANOVA und interpretiere die Ergebnisse. Berechne zur Überprüfung der Multikolinearität den Kennwert Tol und VIF (verwende die Funktion vif(). Hinweis: die Toleranz ist der Kehrwert von VIF) Lösung Aufgabe MLR 1 Wahl relevanter Prädiktoren Eine wichtige Frage bei der Modellerstellung betrifft die Wahl der besten Prädiktoren. Prinzipiell sollte bereits im Vorfeld der statistischen Analyse bestimmt werden, welche Merkmale für die Modellierung der abhängigen Variablen am geeignetsten sind. Ausreichende theoretische und praktischen Kenntnisse sind daher unbedingt erforderlich. Prädiktoren sind dann gut geeignet, wenn Sie folgende Eigenschaften erfüllen: jeder Prädiktor erklärt möglichst viel der Variabilität des Kriteriums (\\(|r(y,x_j)| \\gg 0\\)). die Prädiktoren (z.B. \\(x_1\\) und \\(x_2\\)) sind im günstigsten Fall voneinander unabhängig (\\(r(x_i,x_j) \\approx 0\\) mit \\(i \\ne j\\)). Korrelieren zwei Prädiktoren mit \\(r(x_i, x_j) &gt; 0.8\\), kann man schon mit ziemlicher Sicherheit davon ausgehen, dass die Verwendung beider Prädiktoren in einem Modell zu instabilen Regressionskoeffizienten führt und Aussagen zur Schätzung der Regressionskoeffizienten zunehmend ungenau werden (siehe Voraussetzungen der multiplen Regression und Problem der Multikollinearität). Diese Eigenschaft kann man durch eine einfache paarweise Korrelation prüfen. Vor allem wenn die zweite Eigenschaft nicht gegeben ist, also wenn einen hohe Korrelationen zwischen zwei Prädiktoren vorliegt, wird es bei der Modellierung zu maßgeblichen Problemen (Multikollinearität) kommen (siehe: Voraussetzungen der multiplen Regression. Neben der Frage nach der Güte einzelner Prädiktoren ist es auch wichtig sich Gedanken über die Anzahl der zu verwendenden Prädiktoren zu machen. Einerseits führt trivialerweise eine höhere Anzahl von Prädiktoren auch zu einer besseren Aufklärung der Varianz im Kriterium. Ausgenommen von Prädiktoren die in keiner Beziehung zum Kriterium stehen, wird jeder zusätzliche Prädiktor mehr oder weniger der verbleibenden Varianz erklären. In den meisten Fällen ist es aber aus zeitlichen/finanziellen oder sonstigen Gründen nicht sinnvoll, eine möglichst große Menge an Prädiktorvariablen zu erheben. Werden zu viele erklärende Variablen zur Spezifizierung eines Modells verwendet, wird die tatsächliche (geringere) Anpassungsgüte verschleiert. Das Modell wird zwar besser auf die Daten der Stichprobe angepasst, allerdings besteht aufgrund fehlender Generalität keine Übertragbarkeit auf die Grundgesamtheit. Grundsätzlich sollte wie bereits erwähnt die Wahl der Prädiktoren auf theoretisch und praktisch fundierten Grundlagen erfolgen. Welche der zur Verfügung stehenden Prädiktoren im Endeffekt für das Modell verwendet werden, kann anhand der Modellvergleiche auch im statistischen Sinn evaluiert werden. Bei der bisher besprochenen Vorgehensweise der Modellerstellung obliegt es dem Analysten, die zu verwendenden Prädiktoren zu bestimmen. Eine weitere Möglichkeit bietet die sogenannte sequentielle Vorgehensweise, bei der die Ein- und Ausschlusskriterien für Prädiktoren durch statistische Kriterien getroffen werden. Sequentielle Modellbildung In manchen Fällen sind nicht ausreichende theoretische Grundlagen und Erfahrungswerte bezüglich der Wirksamkeit und Wichtigkeit von Prädiktoren vorhanden. In solchen Fällen kann ein exploratives Vorgehen bei der Modellerstellung sehr hilfreich sein. Die nachfolgend beschriebene sequentielle Modellierung entspricht einem solchen Ansatz. Bei der sequentiellen Modellbildung wird ein Modell schrittweise mit unabhängigen Variablen erweitert. In der Regel wird jene Variable, die das \\(R^2\\) am meisten vergrößert (und damit die Vorhersage am meisten verbessert) hinzugefügt. Abhängig von der Anzahl der verfügbaren Prädiktoren wird die Bildung neuer Modelle entweder abgebrochen, wenn weitere Variablen keinen weiteren statistischen signifikanten Beitrag zur Varianzaufklärung mehr leisten, oder wenn keine weiteren Variablen zur Verfügung stehen. Aufgrund der statistischen (maschinellen) Entscheidung über die Verwendung von Prädiktoren, wird diese Vorgehensweise vielfach kritisiert. Nehmen wir in einem sehr einfachen Beispiel einmal an, es stehen 2 Prädiktoren (\\(x_1, x_2\\)) zur Vorhersage der abhängigen Variablen zur Verfügung. Der Prädiktor \\(x_1\\) klärt geringfügig weniger Varianz des Kriteriums auf als Prädiktor \\(x_2\\), ersterer ist aber inhaltlich sinnvoller, leichter zu interpretiern und vor allem weit kostengünstiger zu erfassen. Bei der sequentiellen Methode könnte aber aufgrund des Abbruchkriteriums (Signifikanz des Beitrags) genau dieser Prädiktor vom Modell ausgeschlossen werden. Bei der sequentiellen Methode unterscheidet man noch unterschiedliche Vorgehensweisen hinsichtlich des Hinzufügens/Entfernens von Variablen: Vorwärts-Selektion (FORWARD): Die Variablen werden sequenziell in das Modell aufgenommen. Diejenige unabhängige Variable, welche am stärksten mit der abhängigen Variable korreliert wird zuerst zum Modell hinzugefügt. Dann wird jene der verbleibenden Variablen hinzugefügt, die die höchste partielle Korrelation mit der abhängigen Variablen aufweist. Dieser Schritt wird wiederholt, bis sich die Modellgüte (R-Quadrat) nicht weiter signifikant erhöht oder alle Variablen ins Modellaufgenommen worden sind. Schrittweise (STEPWISE): Diese Methode ist ähnlich wie “Vorwärts”-Selektion, es wird aber zusätzlich bei jedem Schritt getestet, ob die am wenigsten “nützliche” Variable entfernt werden soll. Rückwärts-Elimination (BACKWARD): Zunächst sind alle Variablen im Regressionsmodell enthalten und werden anschließend sequenziell entfernt. Schrittweise wird immer diejenige unabhängige Variable entfernt, welche die kleinste partielle Korrelation mit der abhängigen Variable aufweist, bis entweder keine Variablen mehr im Modell sind oder keine die verwendeten Ausschlusskriterien erfüllen. Im Unterschied zur STEPWISE-Methode wird nicht mehr geprüft, ob die am wenigsten nützliche Variable entfernt werden soll - diese bleibt somit im Modell! Diese Methoden unterscheiden sich von der sogenannten Einschlussmethode (ENTER), bei der alle Variablen gleichzeitig in das Modell eingefügt werden. Die Enter-Methode wird angewendet, wenn das Modell auf theoretischen Überlegungen basiert. Das heißt, sie eignet sich um Theorien zu testen, während die übrigen Methoden eher im Rahmen explorativer Studien eingesetzt werden können. Modellvergleiche Nach einer (explorativen) Analyse der Daten und der Wahl einer passenden Modellklasse, geht es darum, das bestmögliche Modell zu den vorliegenden Daten zu finden. Daher stellt sich die Frage, was “bestmögliches” Modell bedeutet und wie ein solches bestimmt werden kann. In diesem Zusammenhang wird der Gedanke aufgegriffen, dass mit keinem Regressionsmodell die Realität 1:1 abgebildet werden kann. Nimmt man zu viele erklärende Variablen auf, läuft man in Gefahr das Modell zu “overfitten” (Überanpassung). Ein überangepasstes Modell erklärt die zum Schätzen verwendete abhängige Variable meist sehr gut, schneidet jedoch in der Vorhersage von Daten außerhalb der verwendeten Stichprobe häufig schlecht ab. Auf der anderen Seite kann ein Modell auch “underfitted” sein, d.h. die aufgenommenen unabhängigen Variablen können die abhängige Variable nur sehr unzureichend erklären. Modellselektion ist ein allgegenwärtiges Thema in der Statistik/Regressionsanalyse. Dennoch gibt es keine absoluten, objektiven Kriterien anhand derer entschieden werden kann, ob das eine oder das andere Modell gewählt werden sollte. Vielmehr existieren viele verschiedene Verfahren, die versuchen zwischen möglichst viel Erklärungsgehalt des Modells und möglichst wenig Komplexität abzuwägen (siehe dazu Ockhams Rasiermesser) . In einem Artikel von (Yamashita 2007) wurden folgende Methoden für den Vergleich von Regressionsmodellen untersucht: Partial F Partial Correlation Semi-Partial Correlation Akaike Information Criteria (AIC) Die Autoren schließen aus den Ergebnissen ihrer Untersuchung, dass alle Methoden zu den gleichen Ergebnissen, d.h. zur gleichen Modellentscheidung gelangen. Da aber der AIC einerseits leicht zu interpretieren und andererseits auch auf nichtlineare Modelle und Modelle die auf nicht normalverteilten Daten beruhen zu erweitern ist, wird die Anwendung dieses Kriteriums empfohlen. Aikaike (AIC) Das AIC dient also dazu, verschiedene Modellkandidaten zu vergleichen. Dies geschieht anhand des Wertes der log-Likelihood, der umso größer ist, je besser das Modell die abhängige Variable erklärt. Um nicht komplexere Modelle als durchweg besser einzustufen wird neben der log-Likelihood noch die Anzahl der geschätzten Parameter als Strafterm mitaufgenommen. \\[\\begin{equation} AIC_k = 2 \\cdot |k| - 2\\cdot \\hat{L}_k \\tag{4} \\end{equation}\\] In der Formel steht \\(k\\) für die Anzahl der im Modell enthaltenen Parameter und \\(\\hat{L}_k\\) für den Wert der log-Likelihoodfunktion. Gemäß dem Eigenschaften dieser Kennzahl wird also jenes Modell \\(k\\) gewählt, welche den kleinsten AIC aufweist. Das AIC darf nicht als absolutes Gütemaß verstanden werden. Auch das Modell, welches vom Akaike Kriterium als bestes ausgewiesen wird, kann eine sehr schlechte Anpassung an die Daten aufweisen. Die Anpassung ist lediglich besser als in den Alternativmodellen. Die praktische Bedeutung soll anhand eines einfachen Beispiels und der Verwendung des Kriteriums bei unseren Beispieldaten erläutert werden. Nehmen wir an, dass drei Modellvergleiche (\\(mod_1\\), \\(mod_2\\), \\(mod_3\\)) folgende AIC-Werte ergeben haben: \\(AIC_1 = 100, AIC_2 = 102, AIC_3 = 110\\). Berechnet man \\(e^{(AIC_{min} - AIC_i)/2}\\), kann das Ergebnis folgendermaßen interpretiert werden: Beim \\(mod_2\\) ist es um das \\(e^{(100-102)/2} = 0.368\\)-fache wahrscheinlicher den Informationsverlust zu verringern als bei Modell 1 (\\(mod_1\\)). Beim \\(mod_3\\) ist es um das \\(e^{(100-110)/2} = 0.007\\)-fache wahrscheinlicher den Informationsverlust zu verringern als bei Modell 1 (\\(mod_1\\)). Bei diesem Beispiel würde man also \\(mod_3\\) für weitere Betrachtungen ausschließen. Nachdem aber die Modelle \\(mod_1\\) und \\(mod_2\\) sehr nahe beisammen liegen, ist es mit den vorliegenden Daten nicht möglich, eine klare Entscheidung für eines der beiden Modelle zu treffen. Man könnte durchaus noch zusätzliche Daten erheben um dadurch eventuell eine klarere Trennung der beiden Modelle (\\(mod_1\\), \\(mod_2\\)) zu erkennen. Ist das nicht möglich, könnte man beide Modelle mit der relativen likelihood gewichten und auf eine statistische Signifikanz testen, oder davon ausgehen, dass mit den vorliegenden Daten eine Modellwahl eben nicht eindeutig zu treffen ist. Kreuzvalidierung Die Vorhergehensweise bei der Kreuzvalidierung ist relativ simpel: Erstelle ein/mehrere Modell(e) und berechne die jeweiligen Modellparameter \\(b_i^j\\) (mit \\(j = j\\)-tes Modell und \\(i = i\\)’ter Parameter) mit einer Teilmenge der zur Verfügung stehenden Daten (z.B. Training_Data \\(\\subset\\) DF). Verwende die restlichen Daten um mit den entsprechenden Modellen Vorhersagen zu berechnen. Berechne die Differenz der beobachteten Daten und der vorhergesagten Daten. Diese Differenz entspricht dem Fehler des Modells (\\(\\rightarrow \\epsilon_i\\)). Berechne den mittleren quadratischen Fehler der Differenzen. Im nachfolgenden Beispiel soll die Berechnung/Durchführung des AIC und der Kreuzvalidierung anhand simulierter Daten gezeigt und diskutiert werden. AIC und Kreuzvalidierung in R Kopier den nachfolgenden Code in dein R-Script und führe diesen Zeilenweise aus. # AIC &amp; BIC vs. Crossvalidation # https://www.r-bloggers.com/aic-bic-vs-crossvalidation/ # Erzeuge einen Praediktor (gleichverteilt zwischen -2 und +2) x &lt;- runif(100,-2,2) # Erzeuge ein Kriterium (Polynom dritter Ordnung mit zufalligen, normalverteilten Noise) y &lt;- 2*x^3 + x^2 - 2*x +5 + rnorm(100) xy &lt;- data.frame(x=x, y=y) # Definiere das Maximum fuer des Polynoms mit dem die Daten # modelliert werden sollten. MaxPoly &lt;- 5 # Erzeuge einen Datenframe in welche die Modellvorhersagen gespeichert werden. x.new &lt;- seq(min(x), max(x), by=0.1) degree &lt;- rep(1:MaxPoly, each=length(x.new)) predicted &lt;- numeric(length(x.new)*MaxPoly) new.dat &lt;- data.frame(x=rep(x.new, times=MaxPoly), degree, predicted) # MODELLANPASSUNG durch Polynome der Ordnung 1 (linear) bis 7 for(i in 1:MaxPoly){ model &lt;- lm(y ~ poly(x, i)) new.dat[new.dat$degree==i,3] &lt;- predict(model, newdata = data.frame(x = x.new)) } # Daten und angepasste Modelle anzeigen p &lt;- ggplot() + geom_point(aes(x, y), xy, colour=&quot;blue&quot;) + geom_line(aes(x, predicted, colour=as.character(degree)), new.dat) + scale_colour_discrete(name = &quot;Degree&quot;) + theme_bw() print(p, comment = FALSE) # Leeren Datenframe fuer Speichern aller AIC und BIC Werte aller Modelle erzeugen AIC.BIC &lt;- data.frame(criterion = c(rep(&quot;AIC&quot;,MaxPoly), rep(&quot;BIC&quot;,MaxPoly)), value = numeric(MaxPoly*2), degree = rep(1:MaxPoly, times=2)) # Berechnen von AIC/BIC fuer jedes Modell for(i in 1:MaxPoly) { AIC.BIC[i,2] &lt;- AIC(lm(y~poly(x,i))) AIC.BIC[i+MaxPoly,2] &lt;- BIC(lm(y~poly(x,i))) } # FUNKTION zur Kreuzvalidierung mit &quot;leave one out&quot; fuer y ~ poly(x, degree) Polynome crossvalidate &lt;- function(x, y, degree) { preds &lt;- numeric(length(x)) for(i in 1:length(x)) { x.in &lt;- x[-i] x.out &lt;- x[i] y.in &lt;- y[-i] y.out &lt;- x[i] m &lt;- lm(y.in ~ poly(x.in, degree=degree) ) new &lt;- data.frame(x.in = seq(-3, 3, by=0.1)) preds[i] &lt;- predict(m, newdata=data.frame(x.in=x.out)) } # Berechnen des quadratischen Fehlers return(sum((y - preds)^2)) } # Kreuzvalidierung und Speichern der quadratischen Fehler aller Modelle a &lt;- data.frame(cross=numeric(MaxPoly)) for(i in 1:MaxPoly) { a[i,1] &lt;- crossvalidate(x, y, degree=i) } # Anzeige der AIC gegen die Modlellkomplexitaet (= Grad des Ploynoms) AIC.plot &lt;- qplot(degree, value, data=AIC.BIC, geom=&quot;line&quot;, linetype=criterion) + xlab(&quot;Grad des Polynoms&quot;) + ylab(&quot;Abhaengie Variablenwerte&quot;) + labs(title=&quot;Informationstheory &amp; Bayes&quot;) + geom_segment(aes(x=3, y=400, xend=3, yend=325), arrow = arrow(length = unit(0.3, &quot;cm&quot;), angle=20, type=&quot;closed&quot;)) + theme(legend.position=c(0.8,0.5)) + theme_bw() print(AIC.plot, comment = FALSE) # Anzeige der Kreuvalidierten quadratischen Fehler gegen die Modelllkomplexitaet # (Modellkomplexitaet = Grad des Polynoms) cross.plot &lt;- qplot(1:MaxPoly, cross, data=a, geom=c(&quot;line&quot;)) + xlab(&quot;Grad des Polynom&quot;) + ylab(&quot;Quadratischer Fehler&quot;) + geom_segment(aes(x = 3, y = 400, xend = 3, yend = 200), arrow = arrow(length = unit(0.3, &quot;cm&quot;), angle = 20, type=&quot;closed&quot;)) + labs(title=&quot;Kreuzvalidierung&quot;) + theme_bw() print(cross.plot, comment = FALSE) Voraussetzungen MLR Folgende Voraussetzungen müssen/sollten bei der linearen Modellierung mit mehreren Prädiktoren erfüllt sein, damit die Ergebnisse auch sinnvoll interpretiert werden können (Bemerkung: im folgenden sei die abhängige Variable \\(y\\) und die Prädiktoren mit den Zahlen \\({1, 2, \\cdots, k}\\) bezeichnet): Lineare Beziehung zwischen den Variablen (keine Ausreißer): eine einfache Prüfung erfolgt visuell mit Streudiagrammen, wobei alle Beziehungen, also \\(r_{y\\cdot1}, r_{y\\cdot2}, \\cdots, r_{y\\cdot k}, \\cdots, r_{1\\cdot2}, r_{1\\cdot k}, \\cdots, r_{(k-1)\\cdot k}\\) zu betrachten sind! Varianzgleichheit der Residuen (Homoskädasdizität): auch diese Vorausstung kann visuell geprüft werden. Dabei wird ein Streudiagramm der Residuen erstellt, in welchem auf der x-Achse die standardisierten vorhergesagten Werte und auf der y-Achse doe standardisierten Residuen aufgetragen werden. Heteroskedastizität liegt vor, wenn die Punktewolke nicht gleichverteilt um die Gerade liegen! Abbildung 14: Homoskedastizität vs. Heteroskedastizität Bekannte Verfahren, um die Nullhypothese „Homoskedastizität“ zu überprüfen sind der: * Levene-Test * Goldfeld-Quandt-Test * White-Test * Glejser-Test * RESET-Test * Breusch-Pagan-Test Normalverteilung der Residuen: mittels Histogramm der Fehler zu prüfen - sollte halbwegs normalverteilt sein mit einem Erwartungswert des Fehlers \\(E(\\varepsilon) = 0\\). Unabhängigkeit der Residuen (keine Autokorrelation): verletzt wird diese Voraussetzung, wenn aufeinanderfolgende Werte abhängig sind (z.B. auf einen hohen Wert folgt ein hoher Wert, etc.). Vor allem bei Längsschnittdaten ein Thema, bei welchen die Prüfung durch die Durbin-Watson-Methode empfohlen wird. Es gilt: \\(d = \\frac{\\sum_{i} (e_i - e_{i-1})^2}{\\sum_{i} (e_i)^2}\\) mit \\(d \\approx 2\\), Werte zwischen \\(1.5 &lt; d &lt; 2.5\\) sind noch akzeptabel. Vollständig spezifizierte Modelle: werden maßgebliche Prädiktoren nicht im Modell berücksichtigt, wird es auch kaum gelingen, die Varianz des Kriteriums zufriedenstellend zu erklären. Andererseits bewirken Modelle mit vielen Prädiktoren, dass die \\(\\beta\\)-Gewichte entsprechend klein werden. Bei derartigen Gegebenheiten ist die Stichprobe entsprechend groß zu wählen. Keine Multikollinearität: Multikollinearität bedeutet, dass Prädiktoren existieren, die hoch miteinander korrelieren (z.B. \\(r_{1\\cdot2} &gt; 0.8\\)). Damit wird es für das Modell schwer, den jeweiligen Beitrag den Prädiktoren zuzuordnen. Besteht rein das Interesse an maximaler Varianzaufklärung des Kriteriums, ist eine hohe Multikollinearität zu vernachlässigen - die \\(\\beta\\)-Gewichte der einzelnen Prädiktoren darf man dann allerdings nicht interpretieren. Spielen jedoch gerade diese eine wichtige Rolle, kann man entweder hoch korrelierte Prädiktoren zusammenfassen (eventuell Faktorenanalyse/Clusteranalyse vorher durchführen), oder entsprechende Prädiktoren ausschließen. Allerdings sollte man vor dem Ausschluss von Prädiktoren diese auf eventuelle Suppressionseffekte prüfen. Negative und reziproke Suppression: man spricht von Suppressionseffekten, wenn ein Prädiktor aus einem anderen Prädiktor irrelevante Varianz unterdrückt (suppression) und dadurch die Beziehung zwischen diesem Prädiktor und dem Kriterium erhöht. Solche Effekte können durchaus beträchtlich sein und u.U. auch einen Prädiktor, der nichts mit dem Kriterium an sich zu tun hat (\\(r_{y\\cdot k} \\approx 0\\)), als wichtigen Bestandteil des Modells werden lassen. Die Aufnahme des Suppressors in das Regressionsmodell hat somit den Effekt, den anderen Prädiktor von diesen Fehlereinflüssen zu bereinigen. Erkennbar sind Suppressionseffekte einerseits durch Vorzeichenwechsel bei Korrelationen (Nullter Ordnung, also der Produkt-Moment-Korrelation) vs. \\(\\beta\\)-Gewichten (negative Suppression, bzw. NET-Suppression). D.h., dass für nicht-negative Validitäten8 ist der Prädiktor \\(2\\) ein negativer Suppressor, falls seine partielle Steigung negativ ist, d. h., falls \\(B_2 &lt; 0\\). Eine reziproke Suppression liegt vor, wenn für nicht-negative Validitäten die Korrelation der Prädiktoren negativ ist, d. h., falls \\(r_{1\\cdot2} &lt; 0\\). Weitere Details zu Suppressionseffekten siehe Literatur und Diskriminanzanalyse. Hohe Reliabilität der Prädiktoren und des Kriteriums: Variablen sind hochreliabel, wenn sie weitgehend frei von Zufallsfehlern sind, also bei Messwiederholung ähnliche Ergebnisse liefern. Keine Varianzeinschränkung: eine Einschränkung führt i.A. zu eingeschränkten (niedrigeren) Korrelationen. Z.B.: aus 500 Personen werden 100 augrund eines Aufnahmeverfahrens zu einem Studium zugelassen. Will man die Validität des Aufnahmeverfahrens anhand der Beziehung Studienerfolg und Leistung beim Aufnahmetest prüfen, wird es aufgrund der eingeschränkten Variabilität durch die Aufnahmekriterium zu einer Unterschätzung kommen. Unabgängigkeit der Beobachtungseinheiten: eine Verletzung dieser Voraussetzung, kann zu einer maßgeblichen Reduktion der Teststärke des Modells führen. Z.B. soll die Teamorientierung in einem Unternehmen untersucht werden. Diese wird sicher zwischen den einzelnen Personen variieren, aber darüber hinaus kann diese auch abhängig von der Abteilung sein, in welcher Personen arbeiten. Die Variabilität kann dadurch bei bestimmten Abteilungen stark eingeschränkt sein, was einer Reduktion des Stichprobenumfangs und damit einer Teststärkenreduktion gleichzusetzen ist. In solchen Fällen könnte man eine Multilevel-Analyse (gemischtes hierarchisches Modell) einsetzen! Zusammenfassend lässt sich festhalten, dass eine Verletzung einer/mehrerer dieser Voraussetzungen meistens dazu führt, dass die Genauigkeit der Vorhersage gemindert wird. Relativ einfach zu prüfen sind die ersten drei Voraussetzungen (graphisch, Kennwerte wie Korrelation, etc.). Bei der Überprüfung der restlichen Voraussetzung muss man i.A. auf entsprechende statische Verfahren zurückgreifen, die hier aber nicht näher besprochen werden. Einen Überblick über die Möglichkeiten zur Überprüfung der Voraussetzungen finden Sie z.B. unter (UZH 2018), oder MR2 - (Hemmerich 2018). Referenzen "],
["losungen-1.html", "Lösungen Aufgabe SLR 1 Lsg Aufgabe MLR 1 Lsg", " Lösungen Aufgabe SLR 1 Lsg zurück zur Aufgabenstellung Aufgabe MLR 1 Lsg album2 &lt;- read.delim(&quot;Daten/Album Sales 2.dat&quot;, header = TRUE) # Erstes Modell albumSales.2 &lt;- lm(sales ~ adverts, data = album2) # zweites Modell albumSales.3 &lt;- lm(sales ~ adverts + airplay + attract, data = album2) # Ausgabe Ergebnisse pander::pander(summary(albumSales.2)) pander::pander(summary(albumSales.3)) # Modellvergleich # library(car) fuer VIF anova(albumSales.2, albumSales.3) # library(car) fuer VIF Tol &lt;- 1/car::vif(albumSales.3) VIF &lt;- car::vif(albumSales.3) zurück zur Aufgabenstellung rm(list = ls()) graphics.off() if (!require(&quot;pacman&quot;)) install.packages(&quot;pacman&quot;) pacman::p_load(pander) options(digits=3) "],
["kategorielle-pradiktoren.html", "Kategorielle Prädiktoren Mehrstufiger kategorieller Prädiktor", " Kategorielle Prädiktoren Bei lineare Modellen ist häufig neben intervallskalierten Prädiktorvariablen auch die Verwendung von kategoriellen Variablen von Interesse. So lange der verwendete Prädiktor nur zwei Ausprägungen hat (z.B. männlich/weiblich, Ja/Nein, etc.), stellt dies auch kein Problem dar. Mehrstufiger kategorieller Prädiktor Während eines dreitägigen Musikfestivals wurde bei einer Anzahl freiwilliger TeilnehmerInnen der “Hygienezustand” gemessen (Variablen day1, day2, day3). Der Wertebereich der Messung liegt zwischen 0 und 4, mit 0 = smell like s..t, bis 4 = smell like freshly baked bread9. Darüber hinaus wurden die TeilnehmerInnen über ihre jeweilige Zuordnung zu eine bestimmten, persönlich bevorzugten Musikrichtung (music) befragt. Bei dem Fesitval gaben die TeilnehmerInnen insgesamt vier verschiedenen Musikrichtungen an: Metaller, Crusty, Indie, NMA (= No Music Affiliation). Nach Erfassung der Daten wurde die Differenz der Hygienewerte zwischen dem letzten und dem ersten Tag des Festivals berechnet und in der Variablen change gespeichert: ticknumb music day1 day2 day3 change 1 2111 Metaller 2.65 1.35 1.61 -1.04 2 2229 Crusty 0.97 1.41 0.29 -0.68 10 2504 No Musical Affiliation 1.11 0.44 0.55 -0.56 12 2510 Crusty 0.82 0.2 0.47 -0.35 14 2515 No Musical Affiliation 1.76 1.64 1.58 -0.18 21 2549 Crusty 2.17 0.7 0.76 -1.41 Offenbar liegt bei der Variablen music ein Faktor mit mehr als 2 Stufen (es sind 4) vor. Da die Verwendung von katetoriellen Variablen in einem linearen Modell eine Stufenanzahl von 2 voraussetzt, kann durch geschicktes Kodieren der Variablen diese Voraussetzung auch für mehrstufige Variablen erreicht werden. Daten und Beispiel aus (Field 2017), Kapitel 7.12.1↩ "],
["dummy-kodierung.html", "Dummy Kodierung", " Dummy Kodierung Man nennt diesen Vorgang auch Dummy Kodierung. Die Vorgehensweise ist dabei: Die Anzahl der neuen (Dummy) Variablen ist die Anzahl der Stufen des Prädiktors - 1 \\((N_{DummyVars} = N_{Stufen} - 1)\\) Man legt so viele neue Variablen (Dummy-Variablen) an, wie man (im ersten Schritt) als Anzahl der Gruppen berechnet hat. Wahl einer Bezugsgruppe (Baseline-Bedingung). üblicherweise die Kontrollgruppe, falls keine vorhanden wählt man am besten die Gruppe, in der die meisten Personen/Fälle vorliegen. Allen Dummy-Variablen für die gewählte Baselinegruppe den Zahlenwert 0 zuweisen. Der ersten Dummy-Variablen für die erste Gruppe die man gegen die Baselinegruppe vergleichen will den Wert 1 zuweisen, den restlichen Gruppen den Wert 0. Wiederholung des Schrittes 5, bis alle Dummy-Variablen entsprechend codiert wurden. Alle Dummy-Variablen ins Modell aufnehmen! DVar1 DVar2 DVar2 Crusty 1 0 0 Indie Kid 0 1 0 Metaller 0 0 1 No Affliation 0 0 0 Bei der linearen Modellierung in R werden kategorielle Daten im Modell automatisch Dummy-Kodiert. Will man jedoch eine spezielle Anordung der Gruppen, sollte man wissen, wie eine händische Kodierung einfach durchgeführt werden kann. Im folgenden Code werden diese Möglichkeiten dargestellt: # Automatisch ohne Bezeichnung der Dummyvariablen contrasts(DF$music) &lt;- contr.treatment(4, base = 4) # Manuel mit Bezeichnung der Dummyvariablen crusty_v_NMA &lt;- c(1,0,0,0) indie_v_NMA &lt;- c(0,1,0,0) metal_v_NMA &lt;- c(0,0,1,0) contrasts(DF$music) &lt;- cbind(crusty_v_NMA, indie_v_NMA, metal_v_NMA) pander(attr(DF$music, &quot;contrasts&quot;), digits = 3) crusty_v_NMA indie_v_NMA metal_v_NMA Crusty 1 0 0 Indie Kid 0 1 0 Metaller 0 0 1 No Musical Affiliation 0 0 0 "],
["modelle-mit-kategoriellen-variablen.html", "Modelle mit kategoriellen Variablen", " Modelle mit kategoriellen Variablen Sind die Dummy-Variablen angelegt, kann damit auch das Modell erstellt werden. Im nachfolgenden Beispiel wird die Variable change durch die Dummy-Kodierten Prädiktoren modelliert. Die erste Tabelle zeigt die durchschnittlichen change-Werte pro Musikzugehörigkeitsgruppe. pander(round(tapply(DF$change, DF$music, mean, na.rm = TRUE), 3)) Crusty Indie Kid Metaller No Musical Affiliation -0.966 -0.964 -0.526 -0.554 mod_dummy_1 &lt;- lm(change ~ music, data = DF) AllRes &lt;- summary(mod_dummy_1) pander(anova(mod_dummy_1), digits = 3) Analysis of Variance Table Df Sum Sq Mean Sq F value Pr(&gt;F) music 3 4.65 1.55 3.27 0.0237 Residuals 119 56.4 0.474 NA NA pander(summary.lm(mod_dummy_1), digits = 3) Estimate Std. Error t value Pr(&gt;|t|) (Intercept) -0.554 0.0904 -6.13 1.15e-08 musiccrusty_v_NMA -0.412 0.167 -2.46 0.0152 musicindie_v_NMA -0.41 0.205 -2 0.0477 musicmetal_v_NMA 0.0284 0.16 0.177 0.86 Fitting linear model: change ~ music Observations Residual Std. Error \\(R^2\\) Adjusted \\(R^2\\) 123 0.6882 0.07617 0.05288 Wesentliche Kennzahlen des Ergebnisses: \\(R^2 = 0.076\\): d.h., dass \\(7.6\\%\\) der Variabilität in der Änderung der Hygenewerte zwischen ersten und dritten Tag (change) durch die Zugehörigkeit zu einer Musikgruppe erklärt werden. \\(F(3, 119) = 3.27; p = .053\\) gibt an, dass die \\(7.6\\%\\) Varianzaufklärung statistisch signifikant ist. Das Modell ist also signifikant besser als kein Modell zu verwenden. musiccrusty_vs_NMA: Differenz zwischen der NMA und crusty Gruppe. Betrachtet man die Differenz der Mittelwerte (siehe obige Tabelle) zwischen \\(crusty - NMA = -.966 - (-0.554) = -0.412\\), stellt man fest, dass diese Differenz dem Estimate, also dem \\(b\\)-Koeffizienten entspricht. Offenbar ist die Änderung der Hygienewerte bei crusty höher als bei der NMA \\(\\rightarrow\\) crusties sind größere Schweindln wie die NMA Leute. Die \\(b\\)-Werte geben also die relative Änderung zur Baselinegruppe an! \\(t = -2.46, p = .015\\): tested ob die Differenz signifikant unterschiedlich zu einer Null-Differenz (kein Unterschied) in den Hygienebedingungen ist. Im vorliegenden Fall handelt es sich um eine signifikante Abnahme der Hygienewerte, wenn man von NMA auf crusty wechselt. Die restlichen Koeffizienten sind in gleicher Weise zu interpretieren. rm(list = ls()) graphics.off() if (!require(&quot;pacman&quot;)) install.packages(&quot;pacman&quot;) pacman::p_load(pander, mediation, SciViews) # install.packages(&quot;sjPlot&quot;) # install.packages(&quot;yaml&quot;, dependencies = TRUE) # install.packages(&quot;sjPlot&quot;, dependencies = TRUE) # install.packages(&quot;sjmisc&quot;, dependencies = TRUE) # install.packages(&quot;stringi&quot;, dependencies = TRUE) # install.packages(&quot;httpuv&quot;, dependencies = TRUE) # require(yaml) # require(sjPlot) # require(sjmisc) # options(digits=3) # Verzeichnise InitialisierenCPS85 "],
["mediation.html", "Mediation Konzeptuelles Modell Effektgrößen der Mediation Fallbeispiel", " Mediation Die Mediatior-Analyse kann als Spezialfall der multiplen linearen Regression (MLR) gesehen werden. Wie bei der MLR wollen wir den Zusammenhang mehrerer Variablen untersuchen, wobei in der Mediator-Analyse speziell der Einfluss eines Prädiktors (des Mediators, \\(M\\)) auf die Beziehung zwischen einem weiteren Prädiktor \\(X\\) und dem Kriterium \\(Y\\) im Zentrum des Interesses steht. Bei der Mediation steht der Mediator \\((M)\\) sowohl in Beziehung zu \\(X\\) als auch zu \\(Y\\). Der direkte Effekt zwischen \\(X\\) und \\(Y\\) wird durch den indirekten Effekt über \\(M\\) erklärt, also durch \\(X \\rightarrow M \\rightarrow Y\\). Konzeptuelles Modell Eine Variable bezeichnet man als Mediatorvariable \\(M\\), wenn sie die Beziehung zweier anderer Variablen (\\(X\\) und \\(Y\\)) vermittelt/erklärt. Abbildung 15: Konzeptuelles Modell Mediation Dieser schematischen Darstellung kann man entnehmen, dass die Mediatorvariable dann einen Einfluss auf die Beziehung zwischen dem Prädiktor \\(X\\) und dem Kriterium \\(Y\\) hat, wenn sich die Beziehung zwischen \\(X\\) und \\(Y\\) (im Diagramm Pfad \\(c\\) - totaler Effekt) durch Berücksichtigung des Mediators \\(M\\) ändert. Diese Änderung ist durch den direkten Effekt (im Diagramm Pfad \\(c&#39;\\)) dargestellt. Die Stärke der Änderung und damit auch der Effekt des Mediators lässt sich darüber hinaus durch den indirekten Effekt (\\(a \\cdot b\\)) beurteilen. Um ein Mediatormodell zu prüfen, sind eine Reihe von Regressionsanalysen erforderlich: Eine Regression mit \\(X\\) als Prädiktor und \\(Y\\) als Kriterium. Der daraus resultierende Regressionskoeffizient \\(b_1\\) entspricht dem Pfad c im konzeptuellen Modell. Eine Regression mit \\(X\\) als Prädiktor und \\(M\\) als Kriterium. Der daraus resultierende Regressionskoeffizient \\(b_2\\) entspricht dem Pfad a im konzeptuellen Modell. Eine Regression mit \\(X\\) und \\(M\\) als Prädiktoren und \\(Y\\) als Kriterium. Der daraus resultierende Regressionskoeffizient \\(b_3\\) des Prädiktors \\(X\\) entspricht dem Pfad c’ und der Koeffizient \\(b_4\\) des Mediators \\(M\\) entspricht dem Pfad b im konzeptuellen Modell. Folgende Ergebnisse dieser Modelle würden für den Effekt des Mediators sprechen: Die Regressionkoeffizienten \\(b_1, b_2\\) und \\(b_3\\) (also die Pfade a, b, c im Modell) zeigen ein signifikantes Ergebnis. Der Regressionkoeffizient \\(b_3\\) muss kleiner sein als \\(b_1\\) (\\(c&#39; &lt; c\\) im Modell) Obwohl die Regressionsanalyse die grundlegende Idee der Mediationsanalyse gut zeigt, hat sie den Nachteil, dass der Effekt (Bedeutsamkeit) der Reduktion nicht wirklich klar ersichtlich ist. Häufig findet man noch folgende Kriterien (Baron and Kenny’s Method) für die Entscheidung ob eine Mediation vorliegt: Eine Mediation liegt vor, wenn die Beziehung zwischen Prädiktor und Kriterium ohne Berücksichtigung des Mediators signifikant (p &lt; .05) und mit Berücksichtigung des Mediators nicht mehr signifikant ist. Diese Entscheidungsgrundlage entspricht dem NHST-Testen (all or nothing) und kann zu maßgeblichen Fehlentscheidungen führen, denn: Ein \\(b\\)-Wert kann sich unter Umständen nur um ein wenig ändern, der dazugehörige \\(p\\)-Wert kann sich dabei jedoch ohne weiteres von signifikant auf nicht signifikant ändern! Bei einer großen Änderung des \\(b\\)-Wertes kann es aber auch durchaus vorkommen, dass beide signifikant bleiben! Als alternative Möglichkeiten zur Entscheidungsfindung haben sich folgende Verfahren bewährt: Bootstrap Test: berechnet Konfidenzintervalle für den indirekten Effekt. Liegt der Null-Effekt im CI, kann man davon ausgehen, dass keine Mediation vorliegt, anderenfalls hat man einen Mediator-Effekt gefunden. Diese Methode gibt über den Sobel-Test hinaus auch noch Auskunft über die Güte (Breite des CIs) des gefundenen Mediatior-Effektes. Wenn möglich, sollte diese Methode zur Absicherung des Effektes gewählt werden. Sobel Test: testet den indirekten Effekt (kombinierter Pfad a und b). Liefert dieser Test ein signifikantes Ergebnis, liegt eine signifikante Mediation vor. Allerdings zeigt dieser Test folgende Problembereiche: Die Annahme, dass \\(a \\cdot b\\) eine normalverteilte Stichprobenverteilung besitzt, ist vor allem bei kleinen Stichproben zweifelhaft. Der Test besitzt eine schlecht Power womit große Konfidenzintervall einhergehen. Die Präzision des Tests ist damit in Frage zu stellen! Effektgrößen der Mediation Die einfachste Effektgröße ist der Regressionskoeffizient für den indirekten Effekt und das dazugehörige CI. Der indirekte Effekt ergibt sich aus den kombinierten Effekten der Pfade a und b, also: Unstandardisierter indirekter Effekt: \\(UIE = a \\cdot b\\) Um einerseits den Effekt mit anderen Mediationsmodellen vergleichen zu können, und andererseits einen Kennwert zu berichten, der vor allem in einer Meta-Analyse verwendet werden kann, standardisiert man den indirekten Effekt (index of mediation): Standardisierter indirekter Effekt: \\(SIE = a \\cdot b \\cdot \\frac{s_{X_i}}{s_{Y}}\\) Fallbeispiel Wir betrachten zunächst folgende Hypothese: Die Motivation zu lernen ist einerseits durch die Güte des Unterrichtes und andererseits durch die Erfolge aufgrund der Lernleistung beeinflusst. Man möchte nun herausfinden, welcher der beiden Prädiktoren eine bessere Vorhersage liefert. Dazu wurden in einer Lehr-Lernstudie mit Einzeltutoren von \\(N = 10\\) StudentInnen Daten zur Motivation, Lernleistung und Unterrichtsgüte erfasst. Motivation Lernleistung Unterrichtsguete 98 4 5 98 5 6.5 103 6 7 101 7 5.5 100 8 9 106 10 6.5 111 11 8 125 12 10.5 120 14 8 115 15 10 Regressionsanalyse Wenn wir von der Hypothese ausgehen, dass die Motivation zu lernen durch die Güte des Unterrichts sowie der Lernleistung beeinflusst wird, ist es zunächst von Interesse festzustellen, ob dieses Merkmale überhaupt in Beziehung zueinander stehen. In folgenden rechnen wir daher zuerst die Korrelationen zwischen den Merkmalen. Kopier den Code in ein R-Script und führe diesen aus. Diskutiere die Ergbnisse! # library(SciViews) # fÃ¼r Funktion correlation KorTab &lt;- SciViews::correlation(DF) pander(KorTab, digits = 3) Motivation Lernleistung Unterrichtsguete Motivation 1 0.867 0.741 Lernleistung 0.867 1 0.746 Unterrichtsguete 0.741 0.746 1 plot(KorTab, type = &quot;lower&quot;, digits = 3) Wenn wir nun die Merkmale Lernleistung und Unterrichtsgüte als Regressoren und Motivation als Regressand verwenden, können wir folgendes Modell aufstellen: \\(Motivation = b_0 + b_1 \\cdot Lernleistung + b_2 \\cdot Unterrichtsguete\\) Kopiere den nachfolgenden Code in dein R-Script und führe diesen aus. Diskutiere die Ergebnisse und vergleiche diese mit nachfolgendem statistischen Pfadmodell. Mod1 &lt;- lm(Motivation ~ Lernleistung + Unterrichtsguete, data = DF) Mod1_Std &lt;- lm(scale(Motivation) ~ scale(Lernleistung) + scale(Unterrichtsguete), data = DF) # pander(summary(Mod1), digits = 3) pander(summary(Mod1_Std), digits = 3) Estimate Std. Error t value Pr(&gt;|t|) (Intercept) -3.4e-16 0.172 -1.98e-15 1 scale(Lernleistung) 0.708 0.271 2.61 0.0349 scale(Unterrichtsguete) 0.213 0.271 0.784 0.459 Fitting linear model: scale(Motivation) ~ scale(Lernleistung) + scale(Unterrichtsguete) Observations Residual Std. Error \\(R^2\\) Adjusted \\(R^2\\) 10 0.5424 0.7712 0.7058 Die dargestellten Ergebnisse zeigen die standardisierten Koeffizienten (\\(\\beta_{LL}, \\beta_{UG}\\)). In einem statistischen Pfadmodell lassen sich die bisher gewonnenen Ergebnisse folgendermaßen zusammenfassen: Abbildung 16: statistisches Pfadmodell mit standardisierten Regressionskoeffizienten Dem Ergebnis ist weiters zu entnehmen, dass beide Prädiktoren das Ausmaß der Motivation vorhersagen, wobei die Lernleistung (\\(a = \\beta_{LL} = 0.708\\) und somit \\(R_{LL}^2 = 0.504\\)) sich als der bessere Prädiktor als die Unterrichtsgüte (\\(b = \\beta_{UG} = 0.213\\) und somit \\(R_{UG}^2 = 0.044\\)) herausstellt. Mediator-Analyse Man könnte allerdings auch von folgender Hypothese ausgehen: Je höher die Unterrichtsgüte, desto höher die Motivation und je höher die Motivation der Studenten, desto höher wird die Lernleistung ausfallen. Die Modellvorstellung wäre demnach Unterrichtsgüte \\(\\rightarrow\\) Motivation \\(\\rightarrow\\) Lernleistung. Die Motivation wäre dann nicht ein Effekt der Lernleistung, was bedeutet dass die Kausalwirkung umgekehrt verläuft. In diesem Fall würde die Unterrichtsgüte indirekt über die Mediatorvariable Motivation auf die Lernleistung wirken. Darüber hinaus ist auch anzunehmen, dass die Unterrichtsgüte auch eine direkte Wirkung auf die Lernleistung ausübt. Diese Modellvorstellung lässt sich im folgenden Pfadmodell abbilden: Abbildung 17: Pfadmodell mit standardisierten Regressionskoeffizienten in einem Mediator-Modell Diese Modellvorstellung kann man in folgenden Regressionsberechnungen zerlegen: In der ersten Regression wird die abhängige Variable (Output, Kriterium) Lernleistung durch die unabhängige Variable (Prädiktor) Unterrichtsgüte vorhergesagt. Im vorliegenden Beispiel bezeichnen wir den Steigungskoeffizienten mit \\(b_1\\). Dieser entspricht im konzeptuellen Modell dem Pfad c. Formal entspricht das Modell: \\(Lernleistung = b_0 + b_1 \\cdot Unterrichtsguete\\) Kopiere den nachfolgenden Code in dein R-Script und führe diesen aus. Diskutiere die Ergebnisse und vergleiche diese mit obigen Pfadmodell. Med_Mod_C &lt;- lm(Lernleistung ~ Unterrichtsguete, data = DF) Med_Mod_C_Std &lt;- lm(scale(Lernleistung) ~ scale(Unterrichtsguete), data = DF) # pander(summary(Med_Mod_C), digits = 3) pander(summary(Med_Mod_C_Std), digits = 3) Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 3.57e-17 0.224 1.6e-16 1 scale(Unterrichtsguete) 0.746 0.236 3.16 0.0133 Fitting linear model: scale(Lernleistung) ~ scale(Unterrichtsguete) Observations Residual Std. Error \\(R^2\\) Adjusted \\(R^2\\) 10 0.7068 0.5559 0.5004 In der zweiten Regression betrachten wir den Pfad Unterrichtsgüte zu Motivation (im konzeptuellen Modell der Pfad a), alsoe: \\(Motiviation = b_0 + b_1 \\cdot Unterrichtsguete + \\varepsilon_{Mot}\\) Kopiere den nachfolgenden Code in dein R-Script und führe diesen aus. Diskutiere die Ergebnisse und vergleiche diese mit obigen Pfadmodell. Med_Mod_A &lt;- lm(Motivation ~ Unterrichtsguete, data = DF) Med_Mod_A_Std &lt;- lm(scale(Motivation) ~ scale(Unterrichtsguete), data = DF) # pander(summary(Med_Mod_A), digits = 3) pander(summary(Med_Mod_A_Std), digits = 3) Estimate Std. Error t value Pr(&gt;|t|) (Intercept) -3.15e-16 0.225 -1.4e-15 1 scale(Unterrichtsguete) 0.741 0.238 3.12 0.0143 Fitting linear model: scale(Motivation) ~ scale(Unterrichtsguete) Observations Residual Std. Error \\(R^2\\) Adjusted \\(R^2\\) 10 0.7126 0.5486 0.4922 In der dritten Regression wird nun die Beziehung Unterrichtsgüte und Lernleistung, wie auch Motivation und Lernleistung (im konzeptuellen Modell der Pfad b und c’) überprüft. Das formale Modell lautet also: \\(Lernleistung = b_0 + b_1 \\cdot Unterrichtsguete + b_2 \\cdot Motivation + \\varepsilon_{LL}\\) Kopiere den nachfolgenden Code in dein R-Script und führe diesen aus. Diskutiere die Ergebnisse und vergleiche diese mit obigen Pfadmodell. Med_Mod_CS_B &lt;- lm(Lernleistung ~ Unterrichtsguete + Motivation, data = DF) Med_Mod_CS_B_Std &lt;- lm(scale(Lernleistung) ~ scale(Unterrichtsguete) + scale(Motivation), data = DF) # pander(summary(Med_Mod_CS_B), digits = 3) pander(summary(Med_Mod_CS_B_Std), digits = 3) Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 2.55e-16 0.17 1.5e-15 1 scale(Unterrichtsguete) 0.23 0.267 0.861 0.418 scale(Motivation) 0.696 0.267 2.61 0.0349 Fitting linear model: scale(Lernleistung) ~ scale(Unterrichtsguete) + scale(Motivation) Observations Residual Std. Error \\(R^2\\) Adjusted \\(R^2\\) 10 0.538 0.7749 0.7106 Die bis zu diesem Punkt durchgeführten Analysen lassen uns zwar den Effekt des Mediators erkennen, aber die Abschätzung, ob dieser auch statistisch signifikant ist. Im letzten Schritt unserer Analyse verwenden wir das R-Paket mediation. Kopiere nachfolgenden Code in dein Skript und führe die Zeilen aus. # library(mediation) model.0 &lt;- lm(Lernleistung ~ Unterrichtsguete, DF) model.M &lt;- lm(Motivation ~ Unterrichtsguete, DF) model.Y &lt;- lm(Lernleistung ~ Unterrichtsguete + Motivation, DF) med.out &lt;- mediation::mediate(model.M, model.Y, treat=&#39;Unterrichtsguete&#39;, mediator=&#39;Motivation&#39;, boot=TRUE, sims=500) # summary(model.0) # summary(model.M) # summary(model.Y) # summary.mediate(med.out) Abbildung 18: Ergebnis der Mediator-Analyse Der angegebene totale Effekt (\\(c = b_1 = 1.5395\\)) entspricht dem Effekt von Unterrichtsgüte auf die Lernleistung (ohne Berücksichtigung des Mediators!). Der direkte Effekt (ADE, \\(c&#39; = b_4 = 0.4743\\)) spiegelt den Effelt von Unterrichtsgüte auf Lernleistung unter Berücksichtigung der Motivation wider. Der Mediator-Effekt (ACME) entspricht der Differenz des totalen und direkten Effektes (also \\(c - c&#39; = b_1 - b_4 = 1.5395 - 0.4743 = 1.0651\\)). Das entspricht natürlich auch dem Produkt von \\(a \\cdot b = b_2 \\cdot b_3 = 3.88 \\cdot 0.275 = 1.0651\\). Wird dieser Effekt statistisch signigikant, nimmt man die Hypothese der Wirksamkeit des Mediators an. rm(list = ls()) graphics.off() if (!require(&quot;pacman&quot;)) install.packages(&quot;pacman&quot;) pacman::p_load(DT, ggplot2, interactions, pander) options(digits=3) # Verzeichnise InitialisierenCPS85 "],
["moderation.html", "Moderation", " Moderation Fördert das Spielen von gewalttätigen Videos unsoziales, bzw. aggressives Verhalten? In einer Studie wurde der Zusammenhang zwischen dem Spielen von aggressiven Videos wie z.B. Manhunt, Grand Theft Auto und MadWorld mit Aggression untersucht. Dabei wurden \\(N = 442\\) Jugendliche bezüglich ihres aggressiven Verhaltens (Aggression), den gefühls- und emotionslosen Charaktereigenschaften (Callous Unemotional Traits - CUT, CaUnTs) und der Dauer des Videospielen in Stunden pro Woche (VidGames) aufgezeichnet. Die Daten finden Sie unter Video Games.csv. ID Aggression Vid_Games CaUnTs CaUnTs_Grp 1 27 20 7 Low 2 30 34 14 Low 3 37 20 8 Low 4 29 29 13 Low 5 22 22 15 Low 6 29 34 7 Low Das Ziel der Untersuchung ist es, die Beziehung zwischen Spieldauer (= Prädiktor, Vid_Games) und Aggression (Aggression) genauer zu untersuchen. "],
["konzeptuelles-modell-1.html", "Konzeptuelles Modell Formale Beschreibung des Modells Zentrierung der Variablen", " Konzeptuelles Modell Eine Moderatorvariable ist eine Variable, welche die Beziehung zweier anderer Variablen beeinflusst. Abbildung 18: Konzeptuelles Modell Moderation Im Prinzip stellt sich also die Frage, ob eine Variable (\\(X_1\\)) einen Interaktionseffekt auf die Beziehung der beiden anderen Variablen (\\(Y, X_2\\)) bewirkt. Ein derartiger Interaktionseffekt ist im statistischen Sinne gleichzusetzen mit einem Moderationseffekt (konzeptueller Begriff). Betrachtet man die Beziehung zwischen der abhängigen Variablen (Aggression) und der erklärenden Variablen (Vid_Games): p &lt;- ggplot(DF, aes(x = Vid_Games, y = Aggression)) + geom_point() + geom_smooth(method = lm, se = FALSE) + theme_bw() print(p, comment = FALSE) SumMod1 &lt;- summary(lm(Aggression ~ Vid_Games, data = DF)) pander(SumMod1) Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 34.84 1.96 17.77 1.166e-53 Vid_Games 0.2385 0.08552 2.789 0.005515 Fitting linear model: Aggression ~ Vid_Games Observations Residual Std. Error \\(R^2\\) Adjusted \\(R^2\\) 442 12.5 0.01737 0.01514 scheint die Spieldauer und Aggression nur in einem geringen Ausmaß miteinander in Beziehung zu stehen. Die aufgeklärte Varianz beträgt gerade einmal 1.737%. Ein anderes Bild ergibt sich jedoch, wenn man die Daten unter Berücksichtigung der Variablen CaUnTs betrachtet. Teilt man die Variable CaUnTs z.B. durch einen Mediansplit in zwei Gruppen (CaUnTs_Grp = Low und High), zeigt sich bereits ein sehr unterschiedliches Bild: p1 &lt;- ggplot(DF, aes(x = Vid_Games, y = Aggression, color = CaUnTs_Grp)) + geom_point() + geom_smooth(method = lm, se = FALSE) + theme_bw() print(p1, comment = FALSE) Durch die Trennung können folgende Eigenschaften in den Daten beobachtet werden: Bei Personen die keine CUT aufweisen, besteht keine Beziehung der Spieldauer und der Aggression. Personen die einen CUT aufweisen, zeigen eine positive Beziehung, d.h. je mehr Zeit sie spielen, desto höher wird ihr Aggressionslevel. Die CUT beeinflusst (moderiert) daher die Beziehung der Spieldauer und Aggression. Den Effekt der Variablen CaUnTs (Moderatorvariablen) kann man sich gut durch folgende Darstellung vorstellen: Mod_1 &lt;- lm(Aggression ~ Vid_Games * CaUnTs, data=DF) # plotPlane(model = Mod_1, plotx1 = &quot;Vid_Games&quot;, plotx2 = &quot;CaUnTs&quot;) Abbildung 19: Moderator-Effekt Dass die Moderatorvariable einen Einfluss auf die Beziehung zwischen Vid_Games und Aggression hat, zeigt sich vor allem dadurch dass bei niedrigen CaUnTs-Werten eine negative und bei hohen CaUnTs-Werten eine positive Beziehung zwischen Spieldauer und Aggression besteht. Damit wird auch der Kernpunkt eines Moderationseffektes angesprochen. Ein Moderationseffekt liegt vor, wenn sich die Beziehung zweier Variablen vom Wertebereich des Moderator abhängig ist. Formale Beschreibung des Modells Das lineare Modell einer Moderationsanalyse erweitert die bereits bekannte multiple Regression um den Interaktionsterm: \\(\\widehat{Aggression}_i = (b_0 + b_1 \\cdot Spieldauer_i + b_2 \\cdot Callous_i + b_3 \\cdot Interaktion_i)\\) In den meisten Statistikprogrammen (R, SPSS, SAS, etc.) gibt es Pakete/Makros, mit denen die Moderationsanalyse (u.v.m) speziell aufbereitet wird. Im vorliegenden Fall sollte anhand des einfachen Modells die grundlegende Idee vorgestellte werden. Bei der obigen Formel sind bis auf die Interaktion alle Daten bereits im geladenen Datenmaterial verfügbar. Die Interaktion kann nun sehr leicht aus diesen Daten berechnet und als weitere Variable im Datenframe abgespeichert werden. Dazu braucht man nur die beiden Variablen Vid_Games und CaUnTs multiplizieren und speichern. DF$IA &lt;- DF$Vid_Games*DF$CaUnTs Im nachfolgenden Ergebnis ist vor allem der Interaktionseffekt von Interesse. Ist die Interaktion signifikant, kann man davon ausgehen, dass ein bedeutsamer Moderationseffekt vorliegt. pander(summary(Mod_1)) Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 33.12 3.427 9.664 3.729e-20 Vid_Games -0.3336 0.1508 -2.212 0.0275 CaUnTs 0.1689 0.161 1.049 0.2947 Vid_Games:CaUnTs 0.02706 0.006981 3.877 0.0001221 Fitting linear model: Aggression ~ Vid_Games * CaUnTs Observations Residual Std. Error \\(R^2\\) Adjusted \\(R^2\\) 442 9.976 0.3773 0.373 Bei vorliegender signifikanter Interaktion kann durch eine Simple Slope Analyse (SSA) die Beziehung zwischen Prädiktor und Kriterium für verschiedene Werte des Moderators untersucht werden. Häufig werden dafür drei Werte des Moderators (niedrig = \\(\\bar{x}_{Mod} - sd_{Mod}\\), mittel = \\(\\bar{x}_{Mod}\\), hoch = \\(\\bar{x}_{Mod} + sd_{Mod}\\)) verwendet. In der folgenden Abbildung wurden die Datenpunkte noch zusätzlich nach Ihrer Ausprägung (Größe) bei CaUnTs gewichtet. # library(interactions) # # https://cran.r-project.org/web/packages/jtools/vignettes/interactions.html interact_plot(Mod_1, pred = &quot;Vid_Games&quot;, modx = &quot;CaUnTs&quot;, plot.points = TRUE) Für eine feiner Aufteilung, bzw. Darstellung des Wirkungsbereiches vom Moderator kann über die Johnson und Neymann Methode sehr viele Werte des Moderators berechnen werden. Die entsprechenden \\(b\\)’s werden ermittelt und daraus Signifikanz-Zonen berechnet. Damit werden die Werte des Moderators ermittelt, ab welchen der Prädiktor ein signifikantes Ergebnis liefert. Mod_SS &lt;- lm(Aggression ~ Vid_Games + CaUnTs + (Vid_Games * CaUnTs), data=DF) SS_Res &lt;- sim_slopes(Mod_SS, pred = Vid_Games, modx = CaUnTs, johnson_neyman = TRUE) johnson_neyman(Mod_SS, pred = Vid_Games, modx = CaUnTs, alpha = 0.01) JOHNSON-NEYMAN INTERVAL When CaUnTs is OUTSIDE the interval [-5.35, 18.86], the slope of Vid_Games is p &lt; .01. Note: The range of observed values of CaUnTs is [0.00, 43.00] Zentrierung der Variablen Durch die Berücksichtigung der Interaktion, bekommen die Koeffizienten eine spezielle Bedeutung. Ein Prädiktor \\(X_i\\) repräsentiert die Regression des Kriteriums, wenn die anderen Prädiktoren \\(X_{j \\ne i}\\) gleich Null sind! Im Beispiel: \\(b_1\\) entspricht dem Koeffizienten einer Regression wenn CaUnTs gleich Null ist, also keine Gefühls und emotionslosen Charaktereigenschaften aufweist. \\(b_2\\) entspricht dem Koeffizienten einer Regression wenn VidGames gleich Null ist, also 0 Stunden Video gespielt hat. Im gegebenen Beispiel sind für beide Prädiktoren Null-Werte durchaus möglich. Würde man aber anstelle der Charaktereigenschaften die Herz-Rate der Jugendlichen messen, wäre ein Wert von Null nicht sinnvoll. Aus diesem Grund werden in einer Moderationsanalyse die Prädiktoren transformiert. Man zentriert die Daten auf die Abweichungen des grand averages. Eigenschaften der Zentrierung Das Zentrieren der Prädiktoren ist ähnlich der bekannten z-Transformation, wobei bei der Zentrierung die Division durch die Standardabweichung nicht relevant ist. Formal entsprechen die zentrierten Daten also: \\(X^C_{1i} = X_{1i} - \\bar{X}_{11}\\) Die Zentrierung hat keinen Einfluss auf den Koeffizienten, welcher die meisten Variablen (highest-order-predictor) verknüpft. Im gegebenen Beispiel entspricht das dem Koeffizienten \\(b_3\\), also der Interaktion. Für die Koeffizienten \\(b_1\\) und \\(b_2\\) bewirkt die Zentrierung: \\(b_2\\) zeigt den Effekt zwischen Agression und CUT, wenn jemand die durchschnittliche Spielzeit mit Videospielen verbringt. \\(b_1\\) zeigt den Effekt zwischen Agression und Spieldauer, wenn jemand den durchschnittlichen CUT-Wert haben würde. Gründe für Zentrierung Aus Gründen der Interpretierbarkeit, z.B. \\(y\\) = verbale Fähigkeiten eines Kindes, \\(x_1\\) = Vokabular von der Mutter, \\(x_2\\) = Alter des Kindes: \\(b_0\\) ist nicht sinnvoll interpretierbar, wenn \\(x_1 = 0\\) und \\(x_2 = 0\\) \\(b_0\\) ist aber dann sinnvoll interpretierbar, wenn die Variablen zentriert wurden, denn dann sind die Werte 0 für beide Variablen eben der Mittelwert der zentrierten Variablen! \\(b_1\\) entspricht der Steigung von \\(x_1\\) unter der Annahme eines durchschnittlichen Wertes von \\(x_2\\). Liegt keine Moderation vor, wir \\(b_1\\) konsistent über alle Werte der \\(x_2\\)-Verteilung sein. Liegt ein Moderationseffekt vor, ist \\(b_1\\) nicht konsistent über die Verteilung der \\(x_2\\)-Werte. Aus statistischen Gründen: korrelieren \\(x_1\\) und \\(x_2\\) dann kann es sein, dass auch die Interaktion \\(x_1 \\cdot x_2\\) hoch korreliert! Wenn zwei Prädiktoren in einem GLM hoch miteinander korrelieren, dann sind sie im wesentlichen redundant. Es liegt eine hohe Multikollinearität vor! Es wird auch schwierig, die \\(b\\)-Werte den jeweiligen Prädiktoren zuzuordnen. Bei Zentrierung der Daten kann dieses Problem entschärft werden. Interpretation der \\(b\\)’s Die Zentrierung ermöglicht die Interpretation der Koeffizienten \\(b_1\\) und \\(b_2\\) (lower-order-predictors) auch dann, wenn Null-Werte bei Prädiktoren nicht sinnvoll zu interpretieren sind! Die Interpretation von lower-order-predictors ist nur sinnvoll, wenn die higher-order-predictors nicht signifikant sind! Bei zentrierten Prädiktoren können die \\(b\\)’s von einzelnen Prädiktoren folgendermaßen interpretiert werden: sie zeigen den Effekt des jeweiligen Prädiktors beim Mittelwert der Stichprobe. sie zeigen den durchschnittlichen Effekt des Prädiktors über die Spannweite der Werte des anderen Prädiktors. Bemerkung zu 2: stellen Sie sich vor, dass Sie für jeden möglichen Wert der Spieldauer (VidGames = von 0 bis max(Spieldauer)) jeweils ein lineares Modell rechnen, also ein Modell zur Vorhersage für Aggression durch CUT für die Personen die 0 Std. gespielt haben. Dann dasselbe Modell für jene die 1 Std. gespielt haben, etc. Dadurch ergeben sich z.B. \\(N\\) unterschiedliche \\(b\\)’s, wobei jedes davon den Zusammenhang zwischen CUT und Aggression für unterschiedlich lange Spieldauer zeigt. Würde man den Mittelwert dieser \\(b\\)’s berechnen, dann wäre dieser Wert gleich dem \\(b\\)-Wert für CUT (zentriert) wenn dieser im Moderationsmodell gemeinsam mit der zentrierten Spieldauer (VidGames) und der Interaktion berechnet wird! Interaktion Besteht eine signifikante Interaktion zwischen den beiden Prädiktoren, liegt ein Moderationseffekt vor! Ist die Interaktion \\(CaUnTs \\times Vid\\_Games\\) ein signifikanter Prädiktor für Agression, dann wissen wir zwar dass ein Moderationseffekt vorliegt, aber nicht in welcher Weise! Es könnten folgende Zusammenhänge bestehen: Es könnte sein, dass die Spieldauer immer einen negativen Einfluss auf den Aggressions hat, aber diese Beziehung bei höher werdenden CUT noch wesentlich verstärkt wird. Es könnte sein, dass bei Personen mit niedrigem CUT die Spielzeit die Agression verringert, aber bei Personen mit hohen CUT die Aggression verstärkt. Die Simple Slope Analysis (SSA) bietet bei der Interpretation der Interaktionseffekte eine wesentliche Hilfestellung. "],
["motivation-1.html", "Motivation", " Motivation Die Kovarianzanalyse (ANCOVA) ist ein Spezialfall der ANOVA. Beide werden verwendet, um die Auswirkungen kategorischer Variablen (Faktoren) auf eine intervall- oder ratio-level abhängige Variable zu testen. Die ANCOVA gibt uns jedoch die zusätzliche Möglichkeit, gleichzeitig die Wirkung anderer kontinuierlicher Variablen auf die abhängige Variable zu beurteilen oder zu kontrollieren. Kontinuierliche Variablen, die als Unabhängige in einem ANOVA-Design enthalten sind und die mit einer abhängigen Variablen kovariabel sind, nennt man Kovariablen. Bei der ANCOVA geht es im Wesentlichen darum, die Fehlervarianz bei randomisierten Gruppenexperimenten weiter zu verringern. ANCOVA wird jedoch häufiger eingesetzt, wenn eine Randomisierung nicht möglich ist. In diesen Fällen müssen wir uns oft mit so genannten “nicht-äquivalenten” (nicht zufällig zugeordneten) Gruppen zufrieden geben. Per Definition können sich solche Gruppen in erheblicher Weise unterscheiden, auch bei Merkmalen, die die Ergebnisvariable beeinflussen können. Solange sie nicht berücksichtigt werden, kann das Vorhandensein dieser Hintergrund- oder Fremdvariablen die Fehlervarianz erhöhen, unseren “Signal-Rausch-Abstand” verringern und es letztendlich schwieriger machen, einen echten Unterschied zwischen den Gruppen zu erkennen. "],
["kovarianzanalyse.html", "Kovarianzanalyse Voraussetzungen Berechnung einer ANCOVA Nützliche Graphen Homogenität der Steigung Bericht der Ergebnisse", " Kovarianzanalyse Im folgenden betrachten wir ein Beispiel, welches die Auswirkungen von Viagra auf den Libido untersucht. Es ist naheliegend anzunehmen, dass auch andere Faktoren (wie andere Medikamente, Müdigkeit, etc.) den Libido beeinflussen. Wenn diese Variablen (die Kovariablen) gemessen werden, ist es möglich, den Einfluss, den sie auf die abhängige Variable haben, durch Einbeziehung in das Regressionsmodell zu steuern/kontrolliern. Ziel ist es, den Effekt der Kovariaten auf die Zielvariable zu entfernen. Durch diese Maßnahme sollte sich die Wirkungsweise der unabhängigen Variablen (Viagra) auf den Libodo besser zeigen. Es gibt im Wesentlichen zwei Gründe10 für die Aufnahme von Kovariablen in die ANOVA: Reduzierung der Fehlervarianz: in der ANOVA und beim t-Tests wird die Wirkung eines Experiments anhand der erklärbaren Variabilität in den Daten, mit der nicht erklärbaren Variabiliät verglichen. Wenn ein Teil dieser unerklärten Varianz (SSR) einer anderen Variablen (Kovariablen) zugeordnet werden kann, reduziert sich die Fehlervarianz. Damit kann die Wirkung der unabhängigen Variable (SSM) genauer beurteilt werden. Eliminierung von Confounds: in jedem Experiment kann/wird es Variablen geben, welche nicht gemessen/erhoben wurden, die aber die Ergebnisse der Zielvariablen durchaus beeinflussen können. Sind diese bekannt, kann mit Hilfe der ANCOVA dieser Einfluss beseitigt werden. Im vorliegenden Beispiel gehen wir davon aus, dass der Libido der Sexualpartner den eigenen Libido beeinflusst11. Das entsprechende Regressionsmodell erweitert sich demnach zu: \\(libido_i = b_0 + b_3 \\cdot covariate_i + b_2 \\cdot high_i + b_1 \\cdot low_i + \\varepsilon_i\\) Voraussetzungen Die ANCOVA hat die gleichen Annahmen wie ANOVA, zu welchen es jedoch noch zwei wichtige zusätzliche Überlegungen gibt: Unabhängigkeit von der Kovariablen- und dem Treatmenteffekt. Abbildung 4-A zeigt die bereits aus der ANOVA bekannte Zerlegung der Varianzen in eine Fehlervarianz und einer Treatmentvarianz. Abbildung 4-B stellt eine ideale Voraussetzung für die Verwendung einer Kovariaten dar. Hierbei wird durch die Kovariate ein Teil der Fehlervarianz erklärt, ohne den Effekt des Treatment zu beeinflussen. Abbildung 4-C hingegen zeigt das Problem bei einer fälschlicherweise verwendeten Kovariaten. Die Kovariate verringert zwar nach wir vor die Fehlervarianz, aber gleichzeitig wird auch der Treatmenteffekt beeinflusst. Statistisch gesehen können wir nur festhalten, dass die Kovariate und das Treatment Varianz gemeinsam erkären. Eine Trennung dieser gemeinsamen Varianz in Anteile Viagra und Kovariate ist nicht möglich! Eine einfache Möglichkeit die Kovariate auf ihre Eigenschaft zu prüfen, ist ein einfacher Mittelwertsvergleich (t-Test, ANOVA) der nach Viagragruppen aufgeteilten Kovariaten. Wenn die Gruppen sich nicht unterscheiden, kann von einer Unabhängigkeit ausgegangen werden und sofern die anderen Voraussetzungen erfüllt sind, die Kovariate verwendet werden. Auch durch eine Randomisierung der Gruppenzuordnung kann man unerwünschte Effekte (in Bezug auf die Wirkung der Kovariaten) zwischen den Gruppen evtl. vermeiden. Abbildung 20: Wirkungsweise von Kovariate Zum besseren Verständnis der mit den ANOVA-Verfahren verbundenen Varianzaufteilung betrachten wir nochmals im Detail die Eigenschaften der verschiedenen Varianzanteile. Die Gesamtvarianz (im vorigen Graphen die Varianz von Werten im Libido) wird folgendermaßen ermittelt: Abbildung 21: Totale Quadratsumme Die Treatmentvarianz (im vorigen Graphen die Varianz die durch das Treatment erklärt wird) entspricht der Variabilität der Mittelwerte der jeweiligen Gruppen (in unserem Fall der Dosierungsstufen): Abbildung 22: Treatmentquadratsumme Die Fehlervarianz wird aus den durchschnittlichen Abweichungen der beobachteten Werte zu den jeweiligen Gruppenmittelwerten bestimmt (geschätzt). Anhand dieser Darstellung wird auch klar, warum die Varianzgleichheit über die Gruppen hinweg gleich sein sollte. Wäre das nämlich nicht gegeben, würde die Additivität (\\(QS_1 + \\cdots + QS_k\\) nicht gegeben sein. Abbildung 23: Fehlerquadratsumme Homogenität der Regressionssteigungen. Bei einer ANCOVA wird die Gesamtbeziehung zwischen dem Ergebnis (abhängige Variable) und der Kovariablen analysiert. D.h., es wird eine Regressionslinie an den gesamten Datensatz angepasst und man ignoriert, zu welcher Gruppe eine Person gehört. Bei der Anpassung dieses Gesamtmodells gehen wir daher davon aus, dass diese Gesamtbeziehung für alle Teilnehmergruppen gilt. Diese Annahme ist für die ANCOVA sehr wichtig. Der beste Weg diese Annahme zu kontrollieren, ist eine Darstellung der Kovariablen (Partner’s Libido) auf der einen und dem Ergebnis (Libido) auf der anderen Achse, getrennt nach den Gruppen (Dosierung). Die Regressionslinien sollten dann mehr oder weniger gleich aussehen (d.h. die Werte von \\(b\\) in jeder Gruppe sollten gleich sein). Im nachfolgender Darstellung wäre diese Voraussetung nicht erfüllt! Abbildung 24: Verletzung der Homogenitätsbedingung Berechnung einer ANCOVA Bei der Berechnung einer ANCOVA sollten folgende Schritte durchgeführt werden: Grafischen Darstellung der Daten und der Berechnung einiger deskriptiver Statistiken. Dabei sollten auch die Verteilungsannahmen überprüfen und den Levene-Test durchgeführt werden (Homogenitätstest). Überprüfen der Kovariable und alle unabhängigen Variablen auf Unabhängigkeit, d.h. eine ANOVA mit der Kovariablen als Ergebnis und alle unabhängigen Variablen als Prädiktoren durchführen. Damit wird sichergestellt, dass sich die Kovariable auf den Ebenen dieser Variablen nicht signifikant unterscheidet. Wenn man ein signifikantes Ergebnis erhält, dann ist die Analyse bei diesem Schritt beendet12. Durchführen der ANCOVA. Berechnung der Kontraste oder post hoc-Tests (falls signifikante Ergebnisse vorliegen). Überprüfen der Homogenität der Regressionssteigungen. Dies kann graphisch (siehe oben) durchgeführt werden, oder man kann auch die ANCOVA erneut ausführen und die Interaktion zwischen der unabhängigen Variable und der Kovariablen ins Modell aufnehmen. Wenn diese Interaktion signifikant ist, kann man nicht von einer Homogenität der Regressionsflanken ausgehen! Deskriptive, graphisch und Homogenität Um die Verteilung von Daten darzustellen, kann man z.B. Boxplots für Libido als auch für Libido des Partners erzeugen. Darüber hinaus ist es hilfreich, die Beziehung zwischen der Ergebnisvariablen und der Kovariablen innerhalb jeder Gruppe zu betrachten (dies sagt uns etwas über die Homogenität der Steigungen aus). options(digits = 3) viagraData &lt;- read.delim(&quot;E:/NextCloud/DATEN/CSV_Text/ViagraCovariate.dat&quot;, header = TRUE) viagraData$dose &lt;- factor(viagraData$dose, levels = c(1:3), labels = c(&quot;Placebo&quot;, &quot;Low Dose&quot;, &quot;High Dose&quot;)) restructuredData &lt;- reshape2::melt(viagraData, id = c(&quot;dose&quot;), measured = c(&quot;libido&quot;, &quot;partnerLibido&quot;)) names(restructuredData) &lt;- c(&quot;dose&quot;, &quot;libido_type&quot;, &quot;libido&quot;) boxplot &lt;- ggplot(restructuredData, aes(dose, libido)) + geom_boxplot() + facet_wrap(~libido_type) + labs(x = &quot;Dose&quot;, y = &quot;Libido&quot;) + theme_bw() boxplot Die Boxplots zeigen den Libido bei den Teilnehmern und ihren Partnern über die drei Dosen von Viagra. Die Libido scheint für die Teilnehmer mit zunehmender Dosis von Viagra zu steigen, aber das Gegenteil gilt für ihre Partner. Neben der graphischen Darstellung sind auch die deskriptiven Werte aufschlussreich, da diese Kennwerte wie die Streung (\\(sd\\)) und Mittelwerte (\\(\\bar{x}\\)), Konfidenzintervalle (\\(CI\\)), etc. ausgegeben werden. # library(pastecs) fÃ¼r stat.desc() Res1 &lt;- by(viagraData$libido, viagraData$dose, stat.desc, basic = F, simplify = TRUE) pander(Res1$Placebo) median mean SE.mean CI.mean.0.95 var std.dev coef.var 2 3.222 0.5958 1.374 3.194 1.787 0.5547 pander(Res1$`Low Dose`) median mean SE.mean CI.mean.0.95 var std.dev coef.var 4.5 4.875 0.5154 1.219 2.125 1.458 0.299 pander(Res1$`High Dose`) median mean SE.mean CI.mean.0.95 var std.dev coef.var 4 4.846 0.5867 1.278 4.474 2.115 0.4365 # Res1 &lt;- data.frame(unlist(by(viagraData$libido, viagraData$dose, stat.desc, basic = F))) # colnames(Res1) &lt;- c(&quot;Statistic Libido&quot;) # pander(Res1) Res2 &lt;- by(viagraData$partnerLibido, viagraData$dose, stat.desc, basic = F) pander(Res2$Placebo) median mean SE.mean CI.mean.0.95 var std.dev coef.var 4 3.444 0.6894 1.59 4.278 2.068 0.6005 pander(Res2$`Low Dose`) median mean SE.mean CI.mean.0.95 var std.dev coef.var 2.5 3.125 0.6105 1.444 2.982 1.727 0.5526 pander(Res2$`High Dose`) median mean SE.mean CI.mean.0.95 var std.dev coef.var 2 2 0.4529 0.9868 2.667 1.633 0.8165 # Res2 &lt;- data.frame(unlist(by(viagraData$partnerLibido, viagraData$dose, stat.desc, basic = F))) # colnames(Res2) &lt;- c(&quot;Statistic Partners Libido&quot;) # pander(Res2) pander(stat.desc(viagraData$libido, basic = F)) median mean SE.mean CI.mean.0.95 var std.dev coef.var 4 4.367 0.3571 0.7304 3.826 1.956 0.448 pander(stat.desc(viagraData$partnerLibido, basic = F)) median mean SE.mean CI.mean.0.95 var std.dev coef.var 2.5 2.733 0.3388 0.6929 3.444 1.856 0.6789 Der Test auf Varianzhomogeniät wird mit dem Levene’s-Test durchgeführt. Dabei zeigt sich der Test mit dem Median als zentraler Kennwert robuster als die Schätzung durch den Mittelwert (Bemerkung: man kann auch das Verhältnis der größten zur kleinsten Varianz13 (aus deskriptiver Statistik) bilden und in einer entsprechenden Tabelle auf Signifikanz prüfen). # library(car) fÃ¼r Levenes Test pander(leveneTest(viagraData$libido, viagraData$dose, center = median)) # fÃ¼r robustere SchÃ¤tzung! Levene’s Test for Homogeneity of Variance (center = median) Df F value Pr(&gt;F) group 2 0.3256 0.7249 27 NA NA pander(leveneTest(viagraData$libido, viagraData$dose, center = mean)) Levene’s Test for Homogeneity of Variance (center = mean) Df F value Pr(&gt;F) group 2 0.7112 0.5 27 NA NA Unabhängigkeit Die Unabhängigkeit kann man relativ einfach durch eine ANOVA mit partnerLibido als Ergebnis und Dosis als Prädiktor durchführen. checkIndependenceModel &lt;- aov(partnerLibido ~ dose, data = viagraData) pander(summary(checkIndependenceModel)) Analysis of Variance Model Df Sum Sq Mean Sq F value Pr(&gt;F) dose 2 12.77 6.385 1.979 0.1577 Residuals 27 87.1 3.226 NA NA pander(summary.lm(checkIndependenceModel)) Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 3.444 0.5987 5.753 4.062e-06 doseLow Dose -0.3194 0.8727 -0.366 0.7172 doseHigh Dose -1.444 0.7788 -1.855 0.0746 Fitting linear model: partnerLibido ~ dose Observations Residual Std. Error \\(R^2\\) Adjusted \\(R^2\\) 30 1.796 0.1279 0.06326 PD1 &lt;- data.frame(doBy::summaryBy(partnerLibido ~ dose, data = viagraData, FUN = mean)) colnames(PD1) &lt;- c(&quot;dose&quot;, &quot;PLM&quot;) ggplot(data = PD1, aes(x = dose, y = PLM, fill = dose)) + geom_bar(colour=&quot;black&quot;, stat=&quot;identity&quot;) + theme_bw() guides(fill=FALSE) ## $fill ## [1] FALSE ## ## attr(,&quot;class&quot;) ## [1] &quot;guides&quot; Bei den Koeffizienten (Estimate) des Modells entspricht der Intercept den Mittelwert der ersten Dosierungsstufe (= Placebo) und die weiteren den jeweiligen Abstand zum Mittelwert der Placebodosierung! Berechnung ANCOVA Nach Überprüfung der Voraussetzungen können wir die ANCOVA berechnen. pander(car::Anova(aov(libido ~ partnerLibido + dose, data = viagraData), type = &quot;III&quot;)) Anova Table (Type III tests) Sum Sq Df F value Pr(&gt;F) (Intercept) 12.94 1 4.257 0.0492 partnerLibido 15.08 1 4.959 0.03483 dose 25.19 2 4.142 0.02745 Residuals 79.05 26 NA NA Betrachtet man die Signifikanz-Werte, so ist klar, dass die Kovariable die abhängige Variable signifikant vorhersagt, da \\(F(1,26) = 4.96, p = .035\\) ist. Es ist also davon auszugehen, dass der Libido der Person durch die Libido des Partners beeinflusst wird. Interessant ist, dass nach Berücksichtigung der Wirkung des Libido’s vom Partners die Wirkung von Viagra signifikant ist (\\(F(2,26) = 4.14, p = .028\\)). Wenn wir das nochmals mit den Ergebnissen einer ANOVA (also ohne Berücksichtigung der Kovariaten vergleichen), stellen wir fest, dass durch die Kovariate sich ein nicht signifikantes in ein signifikantes Ergebnis geändert hat. pander(car::Anova(aov(libido ~ dose, data = viagraData), type = &quot;III&quot;)) Anova Table (Type III tests) Sum Sq Df F value Pr(&gt;F) (Intercept) 93.44 1 26.81 1.891e-05 dose 16.84 2 2.416 0.1083 Residuals 94.12 27 NA NA pander(summary.lm(aov(libido ~ partnerLibido + dose, data = viagraData))) Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 1.789 0.8671 2.063 0.0492 partnerLibido 0.416 0.1868 2.227 0.03483 doseLow Dose 1.786 0.8494 2.102 0.04535 doseHigh Dose 2.225 0.8028 2.771 0.01018 Fitting linear model: libido ~ partnerLibido + dose Observations Residual Std. Error \\(R^2\\) Adjusted \\(R^2\\) 30 1.744 0.2876 0.2055 Interpretation ANCOVA Es scheint ziemlich klar zu sein, dass die signifikante ANOVA einen Unterschied zwischen der Placebogruppe und den beiden experimentellen Gruppen widerspiegelt. Anova Table (Type III tests) Sum Sq Df F value Pr(&gt;F) (Intercept) 76.07 1 25.02 3.342e-05 partnerLibido 15.08 1 4.959 0.03483 dose 25.19 2 4.142 0.02745 Residuals 79.05 26 NA NA Dieser Effekt kann damit begründet werden, da niedrig- und hochdosierten Gruppen sehr ähnliche Mittel haben (\\(\\bar{x}_{Low} = 4.88\\), \\(\\bar{x}_{High} = 4.85\\), während der Mittelwert der Placebogruppe bei \\(\\bar{x}_{Placebo} = 3.22\\) viel niedriger ist. Libido Libido_Partner Libido_Adj Placebo 3.222 3.444 2.926 Low Dose 4.875 3.125 4.712 High Dose 4.846 2 5.151 Eigentlich können wir aber diese Gruppenmittel nicht interpretieren, da sie nicht um den Effekt der Kovarianz bereinigt wurden. Diese ursprünglichen Mittel sagen uns nichts über die Gruppenunterschiede, die sich in der signifikanten ANCOVA widerspiegeln! Daher müssen für diesen Vergleich die um den Effekt der Kovariaten bereinigten Mittelwerte verwendet werden. Diese sind in obiger Tabelle in Spalte Libido_Adj angegeben! Geplante Kontraste Für die Berechnung von Kontrasten können entweder vordefinierte Kontrastcodes, oder eigene Kontrastekodierungen angegeben werden14. In R lässt sich z.B. ein Kontrast durch folgende Eingabe definieren: # für orthogonale Kontraste nach Helmert contrasts(viagraData$dose) &lt;- contr.helmert(3) # für Vergleich von Placebo vs. low- und highdose (-2,1,1), sowie low vs. high contrasts(viagraData$dose) &lt; -cbind(c(-2,1,1), c(0,-1,1)) Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 3.126 0.625 5.002 3.342e-05 partnerLibido 0.416 0.1868 2.227 0.03483 dose1 0.6684 0.24 2.785 0.009852 dose2 0.2196 0.4056 0.5414 0.5928 Die Ausgabe des zweiten - oben angegebenen - Kontrastes lässt sich folgendermaßen interpretieren: die erste Variable (Dosis1) vergleicht die Placebogruppe mit der Niedrig- und Hochdosisgruppe. Als solches vergleicht es den angepassten Mittelwert der Placebogruppe (\\(\\bar{x}_{Placebo} = 2.93\\)) mit dem Durchschnitt der angepassten Mittelwerte für die niedrig- und hochdosierten Gruppen (\\((4.71+5.15)/2 = 4.93\\)). der b-Wert für die erste Variable sollte daher die Differenz zwischen diesen Werten sein: \\(4.93 - 2.93 = 2\\). dieser Wert wird durch die Anzahl der Gruppen innerhalb des Kontrastes (d.h. 3) dividiert und somit \\(2/3 = .67\\) (wie in der Ausgabe) beträgt. Die zugehörige \\(t\\)-Statistik ist signifikant, was darauf hindeutet, dass sich die Placebogruppe signifikant vom kombinierten Mittelwert der Viagra-Gruppen unterschied. die zweite Variable (Dosis2) vergleicht die niedrig- und hochdosierten Gruppen, so dass der \\(b\\)-Wert die Differenz zwischen den eingestellten Mitteln dieser Gruppen sein sollte: \\(5.15 - 4.71 = 0.44\\). Dieser Wert wird durch die Anzahl der Gruppen innerhalb des Kontrastes (d.h. 2) dividiert wird und somit \\(0,44/2 = 0,22\\) (wie in der Ausgabe) beträgt. die zugehörige \\(t\\)-Statistik ist nicht signifikant (\\(p = .590\\)), was darauf hindeutet, dass die hochdosierte Gruppe keine signifikant höhere Libido produzierte als die niedrigdosierte Gruppe. der Wert für die Kovariable beträgt (\\(b = 0.416\\)). Wenn also der Libido eines Partners um eine Einheit zunimmt, sollte der Libido der Person um knapp eine halbe Einheit zunehmen (obwohl es nichts gibt, was auf einen kausalen Zusammenhang zwischen den beiden hinweist). das Vorzeichen dieses Koeffizienten zeigt in welche Richtung die Beziehung zwischen der Kovariablen und dem Ergebnis geht. Da der Koeffizient in diesem Beispiel positiv ist, bedeutet dies also, dass die Libido des Partners in einem positiven Verhältnis zur Libido des Teilnehmers steht: mit dem einen steigt auch der andere. ein negativer Koeffizient würde das Gegenteil bedeuten: wenn einer steigt, sinkt der andere. Interpretation Kovariate Für die Interpretatiom der Kovariaten verwendet man am besten die Parameterschätzungen (\\(b\\)) in folgender Weise: wenn der \\(b\\)-Wert für die Kovariable positiv ist, haben die Kovariable und die Ergebnisvariable eine positive Beziehun, also mit zunehmenden Werten der Kovariable steigt auch das Ergebnis! wenn der \\(b\\)-Wert negativ ist, bedeutet das das Gegenteil. Für diese Daten war der \\(b\\)-Wert positiv, was darauf hindeutet, dass mit zunehmender Libido des Partners auch die Libido des Teilnehmers steigt. Eine weitere Möglichkeit, das Gleiche zu entdecken, besteht darin, einfach einen Streudiagramm der Kovariablen gegen das Ergebnis zu zeichnen. Abschließend wird durch den Scatterplot nochmals bestätigt, was wir bereits wissen: die Kovariable bewirkt, dass mit zunehmender Partnerlibido auch die Libido des Teilnehmers zunimmt (wie die Steigung der Regressionslinie zeigt). scatter &lt;- ggplot(viagraData, aes(partnerLibido, libido)) + geom_point(size = 3) + geom_smooth(method = &quot;lm&quot;, alpha = 0.4) + labs(x = &quot;Partner&#39;s Libido&quot;, y = &quot;Participant&#39;s Libido&quot;) + theme_bw() scatter Post hoc Tests Wie bereits aus der ANOVA bekannt sein sollte, werden bei den Post hoc Tests alle Stufen der unabhängigen Variablen paarweise miteinander verglichen. Im Unterschied zur herkömmlichen ANOVA weden jedoch bei der ANCOVA die adjustierten Mittelwerte verwendet! Das Ergebnis zeigt die drei Vergleiche (niedrige Dosis vs. Placebo, hohe Dosis vs. Placebo, hohe Dosis vs. niedrige Dosis). postHocs &lt;- multcomp::glht(viagraModel, linfct = mcp(dose = &quot;Tukey&quot;)) PostHocRes &lt;- summary(postHocs) Verglichen werden die Differenzen zu den adjustierten Gruppenmitteln die Schätzung für die niedrige Dosis vs. Placebo beträgt \\(4.71 - 2.93 = 1.78\\) für die hohe Dosis vs. Placebo beträgt sie \\(5.15 - 2.93 = 2.22\\) und für die niedrige vs. hohe \\(5.15 - 4.71 = 0.44\\) Der angegebene Standardfehler bezieht sich auf die Differenz zwischen den adjusiterten Mittelwerten. Der \\(t\\)-Test (Differenz zwischen den Mitteln geteilt durch den Standardfehler) und dem zugehörigen \\(p\\)-Wert deutet auf signifikante Unterschiede zwischen der Hochdosis- und Placebogruppe (\\(t = 2.77, p &lt; .050\\)) hin. Kein Unterschied besteht zwischen der Niedrigdosisgruppe und der Placebogruppe (\\(t = 2.10, p = .120\\)) und der Hochdosisgruppe (\\(t = 0.54, p = .850\\)). Die Konfidenzintervalle bestätigen diese Schlussfolgerung (weil sie für den Vergleich der Hochdosis- und Placebogruppen Null nicht enthalten). PostHocRes ## ## Simultaneous Tests for General Linear Hypotheses ## ## Multiple Comparisons of Means: Tukey Contrasts ## ## ## Fit: aov(formula = libido ~ partnerLibido + dose, data = viagraData) ## ## Linear Hypotheses: ## Estimate Std. Error t value Pr(&gt;|t|) ## Low Dose - Placebo == 0 1.786 0.849 2.10 0.109 ## High Dose - Placebo == 0 2.225 0.803 2.77 0.026 * ## High Dose - Low Dose == 0 0.439 0.811 0.54 0.852 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## (Adjusted p values reported -- single-step method) confint(postHocs) ## ## Simultaneous Confidence Intervals ## ## Multiple Comparisons of Means: Tukey Contrasts ## ## ## Fit: aov(formula = libido ~ partnerLibido + dose, data = viagraData) ## ## Quantile = 2.48 ## 95% family-wise confidence level ## ## ## Linear Hypotheses: ## Estimate lwr upr ## Low Dose - Placebo == 0 1.786 -0.325 3.896 ## High Dose - Placebo == 0 2.225 0.230 4.220 ## High Dose - Low Dose == 0 0.439 -1.577 2.455 Nützliche Graphen Zur Überprüfung von Voraussetzungen können sich folgende Graphiken als hilfreich erweisen: plot(viagraModel) Von den vier Diagramme sind die ersten beiden die wichtigsten: Ersterer kann zur Überprüfung der Varianzhomogenität der Varianz verwendet werden. Es zeigt sich, dass die Verteilung der Scores an einigen Stellen breiter als an anderenis (Funnelling). Die Residuen sind also heteroscedastisch. Das zweite Diagramm ist ein Q-Q-Diagramm. Die Punkte im Diagramm sollten nahe der diagonalen Linie liegen. Die vorliegende Verteilung deutet darauf hin, dass keine Normalverteilung vorliegt und daher eher eine robuste ANCOVA15 angebracht wäre. Die dritte Graphik wird auch als Spread-Location-Plot bezeichnet. Diese Darstellung zeigt, ob die Residuen gleichmäßig über die Bereiche der Prädiktoren verteilt sind. So können Sie die Annahme der gleichen Varianz (Homoscedastizität) überprüfen. Es ist gut, wenn man eine horizontale Linie mit gleichmäßig (zufällig) gespreizten Punkten sehen - was hier nicht der Fall ist. Die vierte Graphik identifiziert einflussreiche Fälle (Ausreißer). Nicht alle Ausreißer beeinflussen die linearen Regressionsanalyse im negativen Sinn, d.h. die Ergebnisse wären nicht viel anders, wenn wir sie entweder einbeziehen oder von der Analyse ausschließen würden. Sie folgen in den meisten Fällen dem Trend und sind nicht wirklich wichtig. Andererseits können einige Fälle sehr einflussreich sein, auch wenn sie sich in einem angemessenen Bereich der Werte bewegen. Sie können Extremfälle gegen eine Regressionslinie sein und die Ergebnisse verändern, wenn wir sie von der Analyse ausschließen. Im Gegensatz zu den anderen Graphiken sind hier Muster nicht relevant. Man achtet auf die äußeren Werte in der oberen rechten Ecke oder in der unteren rechten Ecke. Diese Punkte sind die Orte, an die für eine Regressionslinie einflussreich sein können. Man beachtet vor allem Fälle, die außerhalb einer gestrichelten Linie (Cook’s Distance) sind. Werte die außerhalb liegen, sind für die Regressionsergebnisse von Bedeutung. Die Regressionsergebnisse werden geändert, wenn wir diese Fälle ausschließen! Homogenität der Steigung Bereits im Scatterplot der nach Gruppen getrennten Regressionen konnten wir feststellen, dass die Annahme der Homogenität der Regressionssteigungen für die Hochdosisgruppe unterschiedlich verletzt wird. Um einen statistischen Test dieser Annahme durchzufürhen, wird die ANCOVA unter Einbeziehung des Interaktionseffektes zwischen der Kovariaten und dem Prädiktor nochmals durchgeführt. hoRS &lt;- aov(libido ~ partnerLibido + dose + dose:partnerLibido, data = viagraData) # Ident mit obiger Zeile! # hoRS &lt;- aov(libido ~ partnerLibido*dose, data = viagraData) hoRS_Res &lt;- car::Anova(hoRS, type=&quot;III&quot;) pander(hoRS_Res) Anova Table (Type III tests) Sum Sq Df F value Pr(&gt;F) (Intercept) 53.54 1 21.92 9.323e-05 partnerLibido 17.18 1 7.035 0.01395 dose 36.56 2 7.484 0.00298 partnerLibido:dose 20.43 2 4.181 0.02767 Residuals 58.62 24 NA NA Die Auswirkungen der Dosis von Viagra und der Libido des Partners sind immer noch signifikant, aber da die Interaktion (partnerLibido:dose) signifikant (\\(p = .028\\)) ist, ist die Annahme der Homogenität der Regressionsgeraden verletzt. Obwohl dieser Befund nicht überraschend ist (vgl. Graphik oben), gibt er Anlass zur Sorge über die Hauptanalyse. Dieses Beispiel veranschaulicht, warum es wichtig ist, Annahmen zu testen und nicht nur die Ergebnisse einer Analyse blind zu akzeptieren! Bericht der Ergebnisse Der Ergebnissbericht einer ANCOVA ist weitgehend identisch mit der einer ANOVA. Hinzu kommt lediglich die Wirkung der Kovariablen. Für die Kovariable und den experimentellen Effekt berichten wir Details über das \\(F\\)-Verhältnis und die Freiheitsgrade, aus denen es berechnet wurde. In beiden Fällen wurde das \\(F\\)-Verhältnis aus der Division der mittleren Quadrate für den Effekt durch die mittleren Quadrate der Residuen ermittelt. Die Freiheitsgrade zur Beurteilung des \\(F\\)-Wertes sind daher die Freiheitsgrade für die Wirkung des Modells (\\(df_M = 1\\) für die Kovariable und \\(2\\) für die experimentelle Wirkung) und die Freiheitsgrade für die Residuen des Modells (\\(df_R = 26\\) für die Kovariable und die experimentelle Wirkung). Der Bericht könnte folgendermaßen abgefasst werden: Die Kovariable (Libido des Partners) zeigt einen signifikanten Zusammenhang mit dem Libido des Teilnehmers (\\(F(1, 26) = 4.96, p &lt; .050, r = 0.40\\). Kontrolliert man für den Effelt des Libido’s des Partners, dann zeigt sich auch ein signifikanter Effekt der Dosis von Viagra auf den Libido (\\(F(2, 26) = 4.14, p &lt; .050, \\eta^2_{part} = .24\\)). Die geplanten Kontraste zeigten, dass die Einnahme einer hohen oder niedrigen Dosis von Viagra den Libido im Vergleich zur Einnahme eines Placebos signifikant erhöht (\\(t(26) = 2,79, p &lt; .010, r = 0.48\\)). Es gab keinen signifikanten Unterschied zwischen der hohen und niedrigen Dosis von Viagra (\\(t(26) = 0.54, p = .590, r = 0.11\\)). Die Tukey-Post-Hoc-Tests zeigten, dass der über die Kovariate angepasste Mittelwert der Hochdosis-Gruppe signifikant größer war als der des Placebos (Differenz = 2.22, \\(t = 2.77, p &lt; .050, d = 1,13\\)). Es gab jedoch keinen signifikanten Unterschied zwischen der Niedrigdosis- und Placebogruppe (Differenz = 1.79, \\(t = 2.10, p = .110, d = 1.04\\)) und zwischen der Niedrigdosis- und der Hochdosisgruppe (Differenz = 0.44, \\(t = 0.54, p = .850, d = 0.11\\)). Trotz der fehlenden Bedeutung zwischen der Niedrigdosis- und der Placebogruppe war die Effektgröße ziemlich groß. Es gibt noch andere Gründe für die Aufnahme von Kovariablen in die ANOVA, welche in der Berechnung der ANCOVA detailliert beschrieben werden. Siehe (Stevens 2002), (Wildt 2009).↩ wie oft sie versuchten, sexuellen Kontakt aufzunehmen.↩ möglicherweise kann man eine robuste Version des Tests ausführen, Details später.↩ Hartely’s \\(F_{max}\\) variance ratio.↩ für eine Liste vordefinierter Kontraste siehe Literatur. Kontraste können sowohl in SPSS wie auch in R durch entsprechende Kontrastcodierungen definiert werden. Bei R ist darauf zu achten, dass bei orthogonalen Kontrasten die Type III sum of squares verwendet wird, da sonst die Quatratsummen für derartige Kontraste nicht stimmen!↩ robuste ANCOVAS werden in dieser LV nicht näher besprochen - siehe Literatur.↩ "],
["referenzen.html", "Referenzen", " Referenzen "]
]
